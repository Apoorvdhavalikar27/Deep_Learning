{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Affordability</th>\n",
       "      <th>Insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Affordability  Insurance\n",
       "0    22              0          0\n",
       "1    25              0          0\n",
       "2    36              1          1\n",
       "3    56              1          1\n",
       "4    89              0          0\n",
       "5    95              0          0\n",
       "6    64              1          1\n",
       "7    75              0          0\n",
       "8    25              0          0\n",
       "9    65              1          1\n",
       "10   61              1          1\n",
       "11   32              1          0\n",
       "12   36              1          1\n",
       "13   45              1          0\n",
       "14   26              1          1\n",
       "15   48              1          0\n",
       "16   56              1          1\n",
       "17   45              1          1\n",
       "18   25              0          0\n",
       "19   22              0          0\n",
       "20   65              1          1\n",
       "21   66              1          1\n",
       "22   74              1          1\n",
       "23   78              1          1\n",
       "24   54              1          1\n",
       "25   62              1          1\n",
       "26   32              0          0\n",
       "27   25              0          0\n",
       "28   55              0          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"DataSets/DL5_DATA.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test  = train_test_split(df[['Age','Affordability']],df.Insurance,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale = X_train.copy()\n",
    "X_train_scale['Age'] = X_train_scale.Age / 100 \n",
    "X_test_scale = X_test.copy()\n",
    "X_test_scale['Age'] = X_test_scale.Age / 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        keras.layers.Dense(1,input_shape = (2,),activation = 'sigmoid',kernel_initializer = 'ones',bias_initializer = 'zeros')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    \n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.6934 - accuracy: 0.4348\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4348\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.4348\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.4348\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.4348\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.4348\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.4348\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.4348\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.4348\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.4348\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.4348\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.4348\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.4348\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.4348\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.4348\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6869 - accuracy: 0.4348\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.4348\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.4348\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.4348\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6853 - accuracy: 0.4348\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.4348\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6844 - accuracy: 0.4348\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6840 - accuracy: 0.4348\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.4348\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.4348\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.4348\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.4348\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.4348\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.4348\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.4348\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.4348\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.4348\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.4348\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.4348\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.4348\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.4348\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6783 - accuracy: 0.4348\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.4348\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.4348\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.4348\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.4348\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.4348\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.4348\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.4348\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.4348\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.4348\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6743 - accuracy: 0.4348\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.4348\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.4348\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.4348\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.4348\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6724 - accuracy: 0.4348\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6720 - accuracy: 0.4348\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6716 - accuracy: 0.4348\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.4348\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6709 - accuracy: 0.4348\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.4348\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.4348\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.4348\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.4348\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.4348\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.4348\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.4348\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.4348\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.4348\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.4348\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.4348\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6664 - accuracy: 0.4348\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6660 - accuracy: 0.4348\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6656 - accuracy: 0.4348\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.6653 - accuracy: 0.4348\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6649 - accuracy: 0.4348\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6645 - accuracy: 0.4348\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.4348\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6638 - accuracy: 0.4348\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.4348\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.4348\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6627 - accuracy: 0.4348\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.4348\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6620 - accuracy: 0.4348\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.4348\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.4348\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.4348\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.4348\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6602 - accuracy: 0.4348\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.4348\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.4348\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.4348\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.4348\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.4348\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.4348\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6578 - accuracy: 0.4348\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.4348\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.4348\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.4348\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.4348\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.4348\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.4348\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6554 - accuracy: 0.4348\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6551 - accuracy: 0.4348\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.4348\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6544 - accuracy: 0.4348\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 983us/step - loss: 0.6540 - accuracy: 0.4348\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.4348\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.4348\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.4348\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.4348\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6524 - accuracy: 0.4348\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.4348\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.4348\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.4348\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6511 - accuracy: 0.4348\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6507 - accuracy: 0.4348\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.4348\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.4348\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.4348\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6494 - accuracy: 0.4348\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.4348\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.4348\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.4348\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.4348\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.4348\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.4348\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.4348\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.4348\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.4348\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6462 - accuracy: 0.4348\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.4348\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.4348\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.4348\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.4348\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.4348\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6444 - accuracy: 0.4348\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6441 - accuracy: 0.4348\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.4348\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.4348\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.4348\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.4348\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6425 - accuracy: 0.4348\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.4348\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.4348\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.4348\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.4348\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.6410 - accuracy: 0.4348\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6407 - accuracy: 0.4348\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.4348\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6401 - accuracy: 0.4348\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6398 - accuracy: 0.4348\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.4348\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6392 - accuracy: 0.4348\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6389 - accuracy: 0.4348\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.4348\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.4348\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6380 - accuracy: 0.4348\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.6377 - accuracy: 0.4348\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6374 - accuracy: 0.4348\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.4348\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.4348\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.4348\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.6362 - accuracy: 0.4348\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.4348\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.4348\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6354 - accuracy: 0.4348\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.4348\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6348 - accuracy: 0.4348\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.4348\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.4348\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6339 - accuracy: 0.4348\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.4348\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.4348\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.4348\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.4348\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.4348\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.4348\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6319 - accuracy: 0.4348\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6317 - accuracy: 0.4348\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.4348\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.4348\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6308 - accuracy: 0.4348\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.4348\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6302 - accuracy: 0.4348\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.4348\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.4348\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.4348\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.4348\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.4348\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.4348\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.4348\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.4348\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.4348\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.4348\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.5217\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.5217\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.5217\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.5217\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.5217\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.5217\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.5217\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.5217\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6250 - accuracy: 0.5217\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6247 - accuracy: 0.5217\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.5217\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.5217\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.5217\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6237 - accuracy: 0.5217\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.5217\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.5217\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.5217\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.5217\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6223 - accuracy: 0.5217\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.5217\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.5217\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.6215 - accuracy: 0.5217\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6957\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6957\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6957\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6205 - accuracy: 0.6957\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.6957\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6957\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6197 - accuracy: 0.6957\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6957\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6957\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6957\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6957\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6957\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6181 - accuracy: 0.6957\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6957\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6957\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6173 - accuracy: 0.6957\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6171 - accuracy: 0.6957\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6168 - accuracy: 0.6957\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6957\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6957\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.6957\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6957\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6957\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6957\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6957\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6957\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6957\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6957\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6957\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6957\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6957\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6957\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6957\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.6957\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6957\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6957\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6957\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6117 - accuracy: 0.6957\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6957\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.6957\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.6109 - accuracy: 0.6957\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6957\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6957\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6957\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.6957\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6097 - accuracy: 0.6957\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6957\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6092 - accuracy: 0.6957\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.6957\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.7391\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.7391\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.6082 - accuracy: 0.7391\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.7391\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7391\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7391\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6072 - accuracy: 0.7391\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7391\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7391\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.7391\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7391\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6059 - accuracy: 0.7391\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6057 - accuracy: 0.7391\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.7391\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7391\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.7391\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7391\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.7391\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.7391\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7391\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6037 - accuracy: 0.7391\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.7391\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6032 - accuracy: 0.7391\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7391\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7391\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.7391\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6022 - accuracy: 0.7391\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6020 - accuracy: 0.7391\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.7391\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6015 - accuracy: 0.7391\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7391\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.7391\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6008 - accuracy: 0.7391\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.7391\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.7391\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7391\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.7391\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5995 - accuracy: 0.7391\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5993 - accuracy: 0.7391\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5991 - accuracy: 0.7391\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7391\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.7391\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5983 - accuracy: 0.7391\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5981 - accuracy: 0.7391\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7391\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7391\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7391\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.7391\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.7391\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5967 - accuracy: 0.7391\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7391\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7391\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5959 - accuracy: 0.7391\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5957 - accuracy: 0.7391\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5955 - accuracy: 0.7391\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7391\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7391\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5947 - accuracy: 0.7391\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5945 - accuracy: 0.7391\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7391\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.7391\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7391\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5936 - accuracy: 0.7391\n",
      "Epoch 326/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7391\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.7391\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7391\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7391\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.7391\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7391\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5919 - accuracy: 0.7391\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7391\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.7391\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5912 - accuracy: 0.7391\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7391\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5907 - accuracy: 0.7391\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7391\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7391\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5900 - accuracy: 0.7391\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7391\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5896 - accuracy: 0.7391\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.7391\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7391\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5889 - accuracy: 0.7391\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5886 - accuracy: 0.7391\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.5884 - accuracy: 0.7391\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7391\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7391\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7391\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7391\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5872 - accuracy: 0.7391\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7391\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7391\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7391\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7391\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7391\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7391\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7391\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7391\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7391\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7391\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5847 - accuracy: 0.7391\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7391\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7391\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7391\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7391\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.5835 - accuracy: 0.7391\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7391\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5831 - accuracy: 0.7391\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7391\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7391\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7391\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7391\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.5820 - accuracy: 0.7391\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.7391\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5815 - accuracy: 0.7391\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5813 - accuracy: 0.7391\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7391\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7391\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7391\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7391\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7391\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5799 - accuracy: 0.7391\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5797 - accuracy: 0.7391\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.7391\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7391\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7391\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7391\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7391\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7391\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7391\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7391\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7391\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7391\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7391\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5770 - accuracy: 0.7391\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7391\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7391\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.7826\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7826\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7826\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5757 - accuracy: 0.7826\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7826\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7826\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7826\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5748 - accuracy: 0.7826\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7826\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5743 - accuracy: 0.7826\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7826\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7826\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5737 - accuracy: 0.7826\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5735 - accuracy: 0.7826\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7826\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7826\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5728 - accuracy: 0.7826\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7826\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7826\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7826\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7826\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7826\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7826\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5713 - accuracy: 0.7826\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7826\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7826\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7826\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7826\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7826\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7826\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7826\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7826\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7826\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5691 - accuracy: 0.7826\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7826\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7826\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7826\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7826\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7826\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7826\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7826\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5674 - accuracy: 0.7826\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7826\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5669 - accuracy: 0.7826\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7826\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7826\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7826\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7826\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5659 - accuracy: 0.7826\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5657 - accuracy: 0.7826\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7826\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7826\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7826\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7826\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7826\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7826\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7826\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7826\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7826\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7826\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5633 - accuracy: 0.7826\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7826\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7826\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7826\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7826\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7826\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7826\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7826\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5617 - accuracy: 0.7826\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7826\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5612 - accuracy: 0.7826\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5610 - accuracy: 0.7826\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7826\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7826\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7826\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7826\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7826\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7826\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7826\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7826\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7826\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7826\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7826\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5585 - accuracy: 0.7826\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5583 - accuracy: 0.7826\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5581 - accuracy: 0.7826\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7826\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7826\n",
      "Epoch 488/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7826\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5573 - accuracy: 0.7826\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7826\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7826\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5567 - accuracy: 0.7826\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7826\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7826\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.8261\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5559 - accuracy: 0.8261\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.8261\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.8261\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.8261\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5550 - accuracy: 0.8261\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5548 - accuracy: 0.8261\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.8261\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5544 - accuracy: 0.8261\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.8261\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5540 - accuracy: 0.8261\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.8261\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5536 - accuracy: 0.8261\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.8261\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.8261\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.8261\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.8261\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5526 - accuracy: 0.8261\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.8261\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.8261\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.8261\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5518 - accuracy: 0.8261\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5516 - accuracy: 0.8261\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.8261\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5512 - accuracy: 0.8261\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5510 - accuracy: 0.8261\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5508 - accuracy: 0.8261\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5506 - accuracy: 0.8261\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.8261\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5502 - accuracy: 0.8261\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.8261\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.8261\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5496 - accuracy: 0.8261\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.8261\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.8261\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.8261\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5488 - accuracy: 0.8261\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5486 - accuracy: 0.8261\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.8261\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8261\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.8261\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5479 - accuracy: 0.8261\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5477 - accuracy: 0.8261\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5475 - accuracy: 0.8261\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.8261\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.8261\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.8261\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.8261\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5465 - accuracy: 0.8261\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.8261\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.8261\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.8261\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5457 - accuracy: 0.8261\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5455 - accuracy: 0.8261\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.8261\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.8261\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5449 - accuracy: 0.8261\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5447 - accuracy: 0.8261\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 905us/step - loss: 0.5445 - accuracy: 0.8261\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5443 - accuracy: 0.8261\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.8261\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.8261\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.8261\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5436 - accuracy: 0.8261\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5434 - accuracy: 0.8261\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.8261\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.8261\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5428 - accuracy: 0.8261\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.8261\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5424 - accuracy: 0.8261\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.8261\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.8261\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.8261\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.8261\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.8261\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5413 - accuracy: 0.8261\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.8261\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.8261\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.8261\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.8696\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5403 - accuracy: 0.8696\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.8696\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5400 - accuracy: 0.8696\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.8696\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.8696\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5394 - accuracy: 0.8696\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.8696\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8696\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5388 - accuracy: 0.8696\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.8696\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.8696\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5383 - accuracy: 0.8696\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.8696\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.8696\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.8696\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5375 - accuracy: 0.8696\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5373 - accuracy: 0.8696\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8696\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.8696\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5368 - accuracy: 0.8696\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.8696\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.8696\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5362 - accuracy: 0.8696\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.8696\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.8696\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.8696\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.8696\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.5353 - accuracy: 0.8696\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.8696\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.8696\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.8696\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5346 - accuracy: 0.8696\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.8696\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8696\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8696\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5338 - accuracy: 0.8696\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5336 - accuracy: 0.8696\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.8696\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.8696\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8696\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.8696\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5327 - accuracy: 0.8696\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5325 - accuracy: 0.8696\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8696\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8696\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.8696\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.8696\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5316 - accuracy: 0.8696\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.8696\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8696\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.8696\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.8696\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5307 - accuracy: 0.8696\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.8696\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.8696\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.8696\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.8696\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.8696\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5297 - accuracy: 0.8696\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.8696\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5293 - accuracy: 0.8696\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.8696\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5290 - accuracy: 0.8696\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.8696\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.8696\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8696\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.8696\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5281 - accuracy: 0.8696\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.8696\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.8696\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5275 - accuracy: 0.8696\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5274 - accuracy: 0.8696\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5272 - accuracy: 0.8696\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5270 - accuracy: 0.8696\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.8696\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8696\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8696\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5263 - accuracy: 0.8696\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.8696\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5259 - accuracy: 0.8696\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.8696\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8696\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5254 - accuracy: 0.8696\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8696\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5251 - accuracy: 0.8696\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8696\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8696\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5246 - accuracy: 0.8696\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8696\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5242 - accuracy: 0.8696\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5240 - accuracy: 0.8696\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8696\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8696\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5235 - accuracy: 0.8696\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8696\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5232 - accuracy: 0.8696\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8696\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.8696\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5227 - accuracy: 0.8696\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5225 - accuracy: 0.8696\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.5223 - accuracy: 0.8696\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5221 - accuracy: 0.8696\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.8696\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.8696\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5216 - accuracy: 0.8696\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.5215 - accuracy: 0.8696\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.8696\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5211 - accuracy: 0.8696\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8696\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8696\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 957us/step - loss: 0.5206 - accuracy: 0.8696\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8696\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.8696\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8696\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8696\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 923us/step - loss: 0.5198 - accuracy: 0.8696\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8696\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8696\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.8696\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8696\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8696\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.8696\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 945us/step - loss: 0.5186 - accuracy: 0.8696\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8696\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8696\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8696\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5179 - accuracy: 0.8696\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8696\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8696\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.5174 - accuracy: 0.8696\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8696\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8696\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8696\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 962us/step - loss: 0.5167 - accuracy: 0.8696\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8696\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.8696\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5163 - accuracy: 0.8696\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.8696\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.5159 - accuracy: 0.8696\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5158 - accuracy: 0.8696\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5156 - accuracy: 0.8696\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8696\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5153 - accuracy: 0.8696\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8696\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8696\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.5148 - accuracy: 0.8696\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8696\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8696\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8696\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5141 - accuracy: 0.8696\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.8696\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8696\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8696\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8696\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8696\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5131 - accuracy: 0.8696\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5130 - accuracy: 0.8696\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8696\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.5127 - accuracy: 0.8696\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8696\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8696\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.8696\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8696\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5118 - accuracy: 0.8696\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5117 - accuracy: 0.8696\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.8696\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5114 - accuracy: 0.8696\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8696\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8696\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.8696\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8696\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.5106 - accuracy: 0.8696\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8696\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5102 - accuracy: 0.8696\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8696\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8696\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8696\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5096 - accuracy: 0.8696\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8696\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5093 - accuracy: 0.8696\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.8696\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8696\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 947us/step - loss: 0.5088 - accuracy: 0.8696\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5087 - accuracy: 0.8696\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8696\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.8696\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.8696\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8696\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.5079 - accuracy: 0.8696\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8696\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5076 - accuracy: 0.8696\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8696\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8696\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5071 - accuracy: 0.8696\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8696\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.8696\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5066 - accuracy: 0.8696\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5065 - accuracy: 0.8696\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5063 - accuracy: 0.8696\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8696\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.8696\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8696\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.8696\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.8696\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.8696\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8696\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.8696\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.5049 - accuracy: 0.8696\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.8696\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5046 - accuracy: 0.8696\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8696\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5043 - accuracy: 0.8696\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8696\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.5040 - accuracy: 0.8696\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5038 - accuracy: 0.8696\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8696\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8696\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5034 - accuracy: 0.8696\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.8696\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8696\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5029 - accuracy: 0.8696\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.8696\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.8696\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8696\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5023 - accuracy: 0.8696\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.5022 - accuracy: 0.8696\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8696\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5019 - accuracy: 0.8696\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5017 - accuracy: 0.8696\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8696\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8696\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.5013 - accuracy: 0.8696\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8696\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8696\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.5008 - accuracy: 0.8696\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8696\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8696\n",
      "Epoch 812/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.5004 - accuracy: 0.8696\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.8696\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.5001 - accuracy: 0.8696\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8696\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8696\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4996 - accuracy: 0.8696\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8696\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8696\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.4992 - accuracy: 0.8696\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8696\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8696\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4987 - accuracy: 0.8696\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4986 - accuracy: 0.8696\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4984 - accuracy: 0.8696\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4983 - accuracy: 0.8696\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8696\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4980 - accuracy: 0.8696\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8696\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8696\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8696\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8696\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4973 - accuracy: 0.8696\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8696\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.8696\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8696\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8696\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8696\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8696\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4963 - accuracy: 0.8696\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4961 - accuracy: 0.8696\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8696\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8696\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8696\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8696\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4954 - accuracy: 0.8696\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4952 - accuracy: 0.8696\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8696\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.8696\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8696\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8696\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.8696\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4944 - accuracy: 0.8696\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8696\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8696\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8696\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8696\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8696\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8696\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8696\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4932 - accuracy: 0.8696\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8696\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8696\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8696\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4927 - accuracy: 0.8696\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.4925 - accuracy: 0.8696\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.8696\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8696\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8696\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8696\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8696\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4917 - accuracy: 0.8696\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8696\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4914 - accuracy: 0.8696\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8696\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8696\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.4910 - accuracy: 0.8696\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8696\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8696\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8696\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8696\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4903 - accuracy: 0.8696\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8696\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.4900 - accuracy: 0.8696\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8696\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8696\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8696\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8696\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4893 - accuracy: 0.8696\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8696\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.4891 - accuracy: 0.8696\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8696\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8696\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8696\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4885 - accuracy: 0.8696\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8696\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4882 - accuracy: 0.8696\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8696\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8696\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8696\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.4877 - accuracy: 0.8696\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8696\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8696\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.4873 - accuracy: 0.8696\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.8696\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8696\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4869 - accuracy: 0.8696\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8696\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8696\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8696\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4863 - accuracy: 0.8696\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8696\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.4861 - accuracy: 0.8696\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.8696\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8696\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4857 - accuracy: 0.8696\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8696\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4854 - accuracy: 0.8696\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.8696\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8696\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8696\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8696\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4847 - accuracy: 0.8696\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4846 - accuracy: 0.8696\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8696\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8696\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8696\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8696\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8696\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8696\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8696\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4835 - accuracy: 0.8696\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4834 - accuracy: 0.8696\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4833 - accuracy: 0.8696\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8696\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4830 - accuracy: 0.8696\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8696\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4827 - accuracy: 0.8696\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8696\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8696\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4823 - accuracy: 0.8696\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8696\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4821 - accuracy: 0.8696\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4820 - accuracy: 0.8696\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8696\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8696\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4816 - accuracy: 0.8696\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8696\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8696\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.8696\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4810 - accuracy: 0.8696\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4809 - accuracy: 0.8696\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8696\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8696\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.8696\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8696\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8696\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8696\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8696\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8696\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8696\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4796 - accuracy: 0.8696\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4795 - accuracy: 0.8696\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8696\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8696\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.4791 - accuracy: 0.8696\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8696\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 991us/step - loss: 0.4789 - accuracy: 0.8696\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8696\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8696\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8696\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.4784 - accuracy: 0.8696\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4782 - accuracy: 0.8696\n",
      "Epoch 974/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8696\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8696\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8696\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4777 - accuracy: 0.8696\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8696\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.8696\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8696\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8696\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8696\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8696\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.4768 - accuracy: 0.8696\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8696\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.8696\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8696\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4763 - accuracy: 0.8696\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8696\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8696\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.8696\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.8696\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8696\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8696\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8696\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8696\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8696\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.8696\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4750 - accuracy: 0.8696\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.4749 - accuracy: 0.8696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c94d51a4f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scale,y_train,epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3305 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33049455285072327, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.26095685],\n",
       "        [1.7173957 ]], dtype=float32),\n",
       " array([-0.822353], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff,intercept = model.get_weights()\n",
    "coeff,intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(ws):\n",
    "    return 1/(1+np.exp(-ws))\n",
    "\n",
    "\n",
    "\n",
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train the model using pure python\n",
    "def gradient_descent(age,affoard,y_true,epoch,loss_threshold):\n",
    "    \n",
    "    rate = 0.01\n",
    "    w1 = w2 = 1\n",
    "    bias = 0\n",
    "    n = len(age)\n",
    "   \n",
    "    for i in range(epoch):\n",
    "        weighted_sum = w1*age + w2*affoard + bias\n",
    "        y_predicted = sigmoid(weighted_sum)\n",
    "        loss =log_loss(y_true, y_predicted)\n",
    "        dw1 = (1/n)*(np.dot(np.transpose(age),(y_predicted -y_true)))\n",
    "        dw2 = (1/n)*(np.dot(np.transpose(affoard),(y_predicted -y_true)))\n",
    "        dbias = np.mean(y_predicted - y_true)\n",
    "        \n",
    "        \n",
    "        w1 = w1- rate*dw1\n",
    "        w2 = w2- rate*dw2\n",
    "        bias = bias - rate*dbias\n",
    "        \n",
    "        print(f'epoch : {i} ,weight1 : {w1} ,weight2 : {w2},bias : {bias}, loss : {loss}')\n",
    "        \n",
    "        if loss <= loss_threshold :\n",
    "            break;\n",
    "            \n",
    "    return w1 ,w2,bias,loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 ,weight1 : 0.9988933005988532 ,weight2 : 0.9996795136328664,bias : -0.0029170160167489518, loss : 0.6933570192551758\n",
      "epoch : 1 ,weight1 : 0.9977897325867533 ,weight2 : 0.9993621491310066,bias : -0.005827458844958833, loss : 0.692374553186619\n",
      "epoch : 2 ,weight1 : 0.9966892933338467 ,weight2 : 0.9990479050264058,bias : -0.008731335628085594, loss : 0.6913968045229045\n",
      "epoch : 3 ,weight1 : 0.9955919801669626 ,weight2 : 0.9987367797960927,bias : -0.011628653588686222, loss : 0.6904237558867561\n",
      "epoch : 4 ,weight1 : 0.9944977903698647 ,weight2 : 0.9984287718623618,bias : -0.01451942002786188, loss : 0.6894553898782149\n",
      "epoch : 5 ,weight1 : 0.993406721183505 ,weight2 : 0.9981238795930001,bias : -0.017403642324698675, loss : 0.6884916890756568\n",
      "epoch : 6 ,weight1 : 0.9923187698062785 ,weight2 : 0.9978221013015153,bias : -0.020281327935706153, loss : 0.6875326360367989\n",
      "epoch : 7 ,weight1 : 0.9912339333942807 ,weight2 : 0.997523435247368,bias : -0.02315248439425357, loss : 0.6865782132997025\n",
      "epoch : 8 ,weight1 : 0.9901522090615659 ,weight2 : 0.9972278796362064,bias : -0.026017119310004045, loss : 0.6856284033837753\n",
      "epoch : 9 ,weight1 : 0.9890735938804074 ,weight2 : 0.9969354326201045,bias : -0.0288752403683466, loss : 0.6846831887907608\n",
      "epoch : 10 ,weight1 : 0.9879980848815594 ,weight2 : 0.9966460922978025,bias : -0.031726855329826255, loss : 0.6837425520057308\n",
      "epoch : 11 ,weight1 : 0.9869256790545199 ,weight2 : 0.9963598567149508,bias : -0.03457197202957216, loss : 0.6828064754980665\n",
      "epoch : 12 ,weight1 : 0.985856373347796 ,weight2 : 0.9960767238643555,bias : -0.037410598376723864, loss : 0.6818749417224373\n",
      "epoch : 13 ,weight1 : 0.9847901646691696 ,weight2 : 0.9957966916862288,bias : -0.04024274235385585, loss : 0.6809479331197735\n",
      "epoch : 14 ,weight1 : 0.9837270498859653 ,weight2 : 0.9955197580684395,bias : -0.0430684120164003, loss : 0.680025432118234\n",
      "epoch : 15 ,weight1 : 0.9826670258253193 ,weight2 : 0.9952459208467688,bias : -0.0458876154920682, loss : 0.6791074211341662\n",
      "epoch : 16 ,weight1 : 0.9816100892744499 ,weight2 : 0.9949751778051661,bias : -0.04870036098026895, loss : 0.6781938825730646\n",
      "epoch : 17 ,weight1 : 0.980556236980929 ,weight2 : 0.9947075266760097,bias : -0.0515066567515284, loss : 0.6772847988305195\n",
      "epoch : 18 ,weight1 : 0.9795054656529547 ,weight2 : 0.9944429651403686,bias : -0.05430651114690546, loss : 0.6763801522931611\n",
      "epoch : 19 ,weight1 : 0.9784577719596262 ,weight2 : 0.9941814908282668,bias : -0.05709993257740735, loss : 0.6754799253395996\n",
      "epoch : 20 ,weight1 : 0.9774131525312186 ,weight2 : 0.9939231013189512,bias : -0.059886929523403534, loss : 0.674584100341356\n",
      "epoch : 21 ,weight1 : 0.9763716039594592 ,weight2 : 0.9936677941411605,bias : -0.06266751053403846, loss : 0.6736926596637909\n",
      "epoch : 22 ,weight1 : 0.9753331227978055 ,weight2 : 0.9934155667733969,bias : -0.06544168422664307, loss : 0.6728055856670231\n",
      "epoch : 23 ,weight1 : 0.9742977055617237 ,weight2 : 0.993166416644201,bias : -0.06820945928614525, loss : 0.6719228607068457\n",
      "epoch : 24 ,weight1 : 0.9732653487289683 ,weight2 : 0.9929203411324272,bias : -0.07097084446447927, loss : 0.6710444671356323\n",
      "epoch : 25 ,weight1 : 0.9722360487398631 ,weight2 : 0.9926773375675229,bias : -0.07372584857999423, loss : 0.6701703873032411\n",
      "epoch : 26 ,weight1 : 0.9712098019975828 ,weight2 : 0.9924374032298088,bias : -0.07647448051686158, loss : 0.6693006035579093\n",
      "epoch : 27 ,weight1 : 0.9701866048684351 ,weight2 : 0.9922005353507621,bias : -0.07921674922448187, loss : 0.6684350982471413\n",
      "epoch : 28 ,weight1 : 0.9691664536821452 ,weight2 : 0.9919667311133011,bias : -0.08195266371689065, loss : 0.6675738537185945\n",
      "epoch : 29 ,weight1 : 0.9681493447321391 ,weight2 : 0.9917359876520722,bias : -0.0846822330721638, loss : 0.6667168523209511\n",
      "epoch : 30 ,weight1 : 0.9671352742758298 ,weight2 : 0.9915083020537384,bias : -0.08740546643182201, loss : 0.6658640764047921\n",
      "epoch : 31 ,weight1 : 0.9661242385349024 ,weight2 : 0.9912836713572709,bias : -0.09012237300023491, loss : 0.6650155083234567\n",
      "epoch : 32 ,weight1 : 0.9651162336956015 ,weight2 : 0.9910620925542409,bias : -0.09283296204402454, loss : 0.6641711304339006\n",
      "epoch : 33 ,weight1 : 0.9641112559090184 ,weight2 : 0.9908435625891145,bias : -0.09553724289146842, loss : 0.6633309250975452\n",
      "epoch : 34 ,weight1 : 0.9631093012913791 ,weight2 : 0.9906280783595489,bias : -0.09823522493190222, loss : 0.6624948746811197\n",
      "epoch : 35 ,weight1 : 0.9621103659243334 ,weight2 : 0.9904156367166904,bias : -0.10092691761512211, loss : 0.6616629615574979\n",
      "epoch : 36 ,weight1 : 0.9611144458552442 ,weight2 : 0.9902062344654741,bias : -0.10361233045078688, loss : 0.6608351681065269\n",
      "epoch : 37 ,weight1 : 0.9601215370974774 ,weight2 : 0.989999868364925,bias : -0.10629147300781978, loss : 0.6600114767158475\n",
      "epoch : 38 ,weight1 : 0.9591316356306925 ,weight2 : 0.9897965351284617,bias : -0.10896435491381029, loss : 0.6591918697817135\n",
      "epoch : 39 ,weight1 : 0.9581447374011337 ,weight2 : 0.9895962314242,bias : -0.11163098585441575, loss : 0.6583763297097955\n",
      "epoch : 40 ,weight1 : 0.9571608383219213 ,weight2 : 0.9893989538752593,bias : -0.11429137557276303, loss : 0.6575648389159848\n",
      "epoch : 41 ,weight1 : 0.956179934273344 ,weight2 : 0.9892046990600706,bias : -0.11694553386885019, loss : 0.6567573798271856\n",
      "epoch : 42 ,weight1 : 0.9552020211031507 ,weight2 : 0.9890134635126843,bias : -0.11959347059894823, loss : 0.6559539348821036\n",
      "epoch : 43 ,weight1 : 0.9542270946268437 ,weight2 : 0.9888252437230814,bias : -0.12223519567500303, loss : 0.6551544865320248\n",
      "epoch : 44 ,weight1 : 0.9532551506279721 ,weight2 : 0.9886400361374851,bias : -0.12487071906403746, loss : 0.6543590172415881\n",
      "epoch : 45 ,weight1 : 0.9522861848584242 ,weight2 : 0.9884578371586731,bias : -0.12750005078755375, loss : 0.6535675094895504\n",
      "epoch : 46 ,weight1 : 0.9513201930387225 ,weight2 : 0.9882786431462922,bias : -0.13012320092093627, loss : 0.6527799457695463\n",
      "epoch : 47 ,weight1 : 0.9503571708583165 ,weight2 : 0.9881024504171738,bias : -0.13274017959285456, loss : 0.6519963085908375\n",
      "epoch : 48 ,weight1 : 0.9493971139758778 ,weight2 : 0.9879292552456502,bias : -0.1353509969846669, loss : 0.6512165804790557\n",
      "epoch : 49 ,weight1 : 0.9484400180195937 ,weight2 : 0.9877590538638723,bias : -0.13795566332982426, loss : 0.650440743976942\n",
      "epoch : 50 ,weight1 : 0.9474858785874621 ,weight2 : 0.9875918424621282,bias : -0.1405541889132749, loss : 0.6496687816450711\n",
      "epoch : 51 ,weight1 : 0.9465346912475864 ,weight2 : 0.987427617189163,bias : -0.14314658407086953, loss : 0.6489006760625778\n",
      "epoch : 52 ,weight1 : 0.9455864515384695 ,weight2 : 0.9872663741525001,bias : -0.14573285918876705, loss : 0.648136409827868\n",
      "epoch : 53 ,weight1 : 0.9446411549693094 ,weight2 : 0.9871081094187618,bias : -0.14831302470284113, loss : 0.6473759655593261\n",
      "epoch : 54 ,weight1 : 0.9436987970202935 ,weight2 : 0.9869528190139931,bias : -0.15088709109808734, loss : 0.6466193258960147\n",
      "epoch : 55 ,weight1 : 0.9427593731428934 ,weight2 : 0.9868004989239841,bias : -0.15345506890803132, loss : 0.6458664734983663\n",
      "epoch : 56 ,weight1 : 0.94182287876016 ,weight2 : 0.986651145094595,bias : -0.15601696871413756, loss : 0.6451173910488687\n",
      "epoch : 57 ,weight1 : 0.9408893092670183 ,weight2 : 0.9865047534320807,bias : -0.15857280114521932, loss : 0.64437206125274\n",
      "epoch : 58 ,weight1 : 0.9399586600305616 ,weight2 : 0.986361319803417,bias : -0.1611225768768493, loss : 0.6436304668386001\n",
      "epoch : 59 ,weight1 : 0.9390309263903465 ,weight2 : 0.986220840036627,bias : -0.16366630663077145, loss : 0.642892590559132\n",
      "epoch : 60 ,weight1 : 0.938106103658687 ,weight2 : 0.9860833099211079,bias : -0.16620400117431366, loss : 0.6421584151917359\n",
      "epoch : 61 ,weight1 : 0.9371841871209489 ,weight2 : 0.9859487252079591,bias : -0.16873567131980186, loss : 0.6414279235391773\n",
      "epoch : 62 ,weight1 : 0.9362651720358438 ,weight2 : 0.9858170816103105,bias : -0.17126132792397486, loss : 0.6407010984302247\n",
      "epoch : 63 ,weight1 : 0.9353490536357231 ,weight2 : 0.9856883748036513,bias : -0.1737809818874007, loss : 0.6399779227202849\n",
      "epoch : 64 ,weight1 : 0.934435827126871 ,weight2 : 0.9855626004261598,bias : -0.1762946441538941, loss : 0.6392583792920237\n",
      "epoch : 65 ,weight1 : 0.9335254876897984 ,weight2 : 0.9854397540790326,bias : -0.17880232570993512, loss : 0.6385424510559862\n",
      "epoch : 66 ,weight1 : 0.9326180304795353 ,weight2 : 0.9853198313268152,bias : -0.18130403758408936, loss : 0.6378301209512036\n",
      "epoch : 67 ,weight1 : 0.9317134506259241 ,weight2 : 0.9852028276977327,bias : -0.18379979084642928, loss : 0.637121371945798\n",
      "epoch : 68 ,weight1 : 0.9308117432339114 ,weight2 : 0.9850887386840208,bias : -0.18628959660795708, loss : 0.6364161870375739\n",
      "epoch : 69 ,weight1 : 0.9299129033838397 ,weight2 : 0.984977559742257,bias : -0.18877346602002903, loss : 0.635714549254608\n",
      "epoch : 70 ,weight1 : 0.9290169261317396 ,weight2 : 0.9848692862936921,bias : -0.19125141027378126, loss : 0.6350164416558265\n",
      "epoch : 71 ,weight1 : 0.9281238065096201 ,weight2 : 0.9847639137245824,bias : -0.19372344059955698, loss : 0.6343218473315783\n",
      "epoch : 72 ,weight1 : 0.9272335395257598 ,weight2 : 0.9846614373865212,bias : -0.19618956826633557, loss : 0.6336307494041988\n",
      "epoch : 73 ,weight1 : 0.9263461201649965 ,weight2 : 0.9845618525967715,bias : -0.19864980458116296, loss : 0.6329431310285681\n",
      "epoch : 74 ,weight1 : 0.925461543389017 ,weight2 : 0.9844651546385979,bias : -0.20110416088858382, loss : 0.6322589753926586\n",
      "epoch : 75 ,weight1 : 0.9245798041366462 ,weight2 : 0.984371338761599,bias : -0.20355264857007552, loss : 0.631578265718079\n",
      "epoch : 76 ,weight1 : 0.9237008973241355 ,weight2 : 0.9842804001820402,bias : -0.20599527904348364, loss : 0.6309009852606077\n",
      "epoch : 77 ,weight1 : 0.922824817845451 ,weight2 : 0.9841923340831858,bias : -0.20843206376245937, loss : 0.6302271173107206\n",
      "epoch : 78 ,weight1 : 0.9219515605725603 ,weight2 : 0.9841071356156316,bias : -0.21086301421589873, loss : 0.62955664519411\n",
      "epoch : 79 ,weight1 : 0.9210811203557198 ,weight2 : 0.9840247998976371,bias : -0.21328814192738357, loss : 0.6288895522721988\n",
      "epoch : 80 ,weight1 : 0.9202134920237601 ,weight2 : 0.9839453220154584,bias : -0.21570745845462444, loss : 0.6282258219426429\n",
      "epoch : 81 ,weight1 : 0.9193486703843722 ,weight2 : 0.9838686970236794,bias : -0.21812097538890549, loss : 0.6275654376398309\n",
      "epoch : 82 ,weight1 : 0.9184866502243912 ,weight2 : 0.9837949199455449,bias : -0.22052870435453117, loss : 0.6269083828353734\n",
      "epoch : 83 ,weight1 : 0.9176274263100812 ,weight2 : 0.9837239857732919,bias : -0.222930657008275, loss : 0.6262546410385861\n",
      "epoch : 84 ,weight1 : 0.916770993387418 ,weight2 : 0.9836558894684811,bias : -0.22532684503883033, loss : 0.6256041957969644\n",
      "epoch : 85 ,weight1 : 0.9159173461823716 ,weight2 : 0.9835906259623289,bias : -0.22771728016626316, loss : 0.6249570306966536\n",
      "epoch : 86 ,weight1 : 0.9150664794011885 ,weight2 : 0.9835281901560381,bias : -0.23010197414146707, loss : 0.6243131293629086\n",
      "epoch : 87 ,weight1 : 0.9142183877306717 ,weight2 : 0.9834685769211285,bias : -0.23248093874562015, loss : 0.6236724754605469\n",
      "epoch : 88 ,weight1 : 0.9133730658384616 ,weight2 : 0.9834117810997681,bias : -0.2348541857896442, loss : 0.6230350526943973\n",
      "epoch : 89 ,weight1 : 0.912530508373315 ,weight2 : 0.9833577975051025,bias : -0.23722172711366601, loss : 0.6224008448097363\n",
      "epoch : 90 ,weight1 : 0.9116907099653833 ,weight2 : 0.9833066209215852,bias : -0.23958357458648094, loss : 0.6217698355927231\n",
      "epoch : 91 ,weight1 : 0.9108536652264904 ,weight2 : 0.9832582461053061,bias : -0.2419397401050186, loss : 0.6211420088708229\n",
      "epoch : 92 ,weight1 : 0.9100193687504093 ,weight2 : 0.9832126677843213,bias : -0.24429023559381088, loss : 0.6205173485132239\n",
      "epoch : 93 ,weight1 : 0.9091878151131378 ,weight2 : 0.9831698806589806,bias : -0.24663507300446233, loss : 0.6198958384312505\n",
      "epoch : 94 ,weight1 : 0.9083589988731734 ,weight2 : 0.9831298794022558,bias : -0.24897426431512262, loss : 0.6192774625787648\n",
      "epoch : 95 ,weight1 : 0.907532914571787 ,weight2 : 0.9830926586600678,bias : -0.2513078215299616, loss : 0.618662204952564\n",
      "epoch : 96 ,weight1 : 0.9067095567332961 ,weight2 : 0.9830582130516132,bias : -0.2536357566786466, loss : 0.6180500495927697\n",
      "epoch : 97 ,weight1 : 0.9058889198653367 ,weight2 : 0.9830265371696907,bias : -0.255958081815822, loss : 0.6174409805832112\n",
      "epoch : 98 ,weight1 : 0.9050709984591343 ,weight2 : 0.9829976255810262,bias : -0.2582748090205917, loss : 0.6168349820518004\n",
      "epoch : 99 ,weight1 : 0.9042557869897736 ,weight2 : 0.9829714728265979,bias : -0.2605859503960032, loss : 0.6162320381709001\n",
      "epoch : 100 ,weight1 : 0.9034432799164678 ,weight2 : 0.9829480734219602,bias : -0.262891518068535, loss : 0.6156321331576876\n",
      "epoch : 101 ,weight1 : 0.9026334716828264 ,weight2 : 0.9829274218575675,bias : -0.265191524187586, loss : 0.6150352512745075\n",
      "epoch : 102 ,weight1 : 0.9018263567171219 ,weight2 : 0.9829095125990964,bias : -0.2674859809249675, loss : 0.6144413768292218\n",
      "epoch : 103 ,weight1 : 0.9010219294325555 ,weight2 : 0.9828943400877681,bias : -0.26977490047439767, loss : 0.61385049417555\n",
      "epoch : 104 ,weight1 : 0.9002201842275226 ,weight2 : 0.9828818987406692,bias : -0.2720582950509989, loss : 0.6132625877134046\n",
      "epoch : 105 ,weight1 : 0.8994211154858751 ,weight2 : 0.9828721829510724,bias : -0.27433617689079715, loss : 0.6126776418892174\n",
      "epoch : 106 ,weight1 : 0.8986247175771849 ,weight2 : 0.9828651870887556,bias : -0.2766085582502245, loss : 0.6120956411962635\n",
      "epoch : 107 ,weight1 : 0.8978309848570047 ,weight2 : 0.9828609055003211,bias : -0.2788754514056239, loss : 0.6115165701749741\n",
      "epoch : 108 ,weight1 : 0.8970399116671288 ,weight2 : 0.9828593325095132,bias : -0.2811368686527568, loss : 0.6109404134132437\n",
      "epoch : 109 ,weight1 : 0.8962514923358516 ,weight2 : 0.9828604624175347,bias : -0.2833928223063129, loss : 0.6103671555467342\n",
      "epoch : 110 ,weight1 : 0.8954657211782254 ,weight2 : 0.9828642895033634,bias : -0.2856433246994237, loss : 0.6097967812591677\n",
      "epoch : 111 ,weight1 : 0.8946825924963181 ,weight2 : 0.982870808024067,bias : -0.2878883881831774, loss : 0.6092292752826157\n",
      "epoch : 112 ,weight1 : 0.8939021005794674 ,weight2 : 0.9828800122151172,bias : -0.29012802512613733, loss : 0.6086646223977812\n",
      "epoch : 113 ,weight1 : 0.8931242397045362 ,weight2 : 0.9828918962907027,bias : -0.29236224791386295, loss : 0.6081028074342739\n",
      "epoch : 114 ,weight1 : 0.8923490041361654 ,weight2 : 0.9829064544440412,bias : -0.2945910689484334, loss : 0.607543815270881\n",
      "epoch : 115 ,weight1 : 0.8915763881270252 ,weight2 : 0.9829236808476908,bias : -0.2968145006479741, loss : 0.6069876308358279\n",
      "epoch : 116 ,weight1 : 0.8908063859180668 ,weight2 : 0.9829435696538595,bias : -0.2990325554461857, loss : 0.6064342391070361\n",
      "epoch : 117 ,weight1 : 0.890038991738771 ,weight2 : 0.9829661149947148,bias : -0.3012452457918762, loss : 0.6058836251123741\n",
      "epoch : 118 ,weight1 : 0.8892741998073967 ,weight2 : 0.9829913109826908,bias : -0.3034525841484958, loss : 0.6053357739299013\n",
      "epoch : 119 ,weight1 : 0.8885120043312279 ,weight2 : 0.9830191517107958,bias : -0.3056545829936741, loss : 0.6047906706881058\n",
      "epoch : 120 ,weight1 : 0.8877523995068188 ,weight2 : 0.9830496312529172,bias : -0.30785125481876086, loss : 0.6042483005661365\n",
      "epoch : 121 ,weight1 : 0.8869953795202389 ,weight2 : 0.9830827436641265,bias : -0.31004261212836903, loss : 0.6037086487940299\n",
      "epoch : 122 ,weight1 : 0.8862409385473152 ,weight2 : 0.9831184829809823,bias : -0.31222866743992084, loss : 0.6031717006529286\n",
      "epoch : 123 ,weight1 : 0.8854890707538746 ,weight2 : 0.9831568432218325,bias : -0.3144094332831967, loss : 0.6026374414752975\n",
      "epoch : 124 ,weight1 : 0.884739770295984 ,weight2 : 0.9831978183871156,bias : -0.316584922199887, loss : 0.6021058566451298\n",
      "epoch : 125 ,weight1 : 0.8839930313201894 ,weight2 : 0.9832414024596601,bias : -0.3187551467431466, loss : 0.6015769315981498\n",
      "epoch : 126 ,weight1 : 0.8832488479637536 ,weight2 : 0.9832875894049831,bias : -0.32092011947715265, loss : 0.6010506518220102\n",
      "epoch : 127 ,weight1 : 0.8825072143548929 ,weight2 : 0.9833363731715877,bias : -0.3230798529766648, loss : 0.6005270028564819\n",
      "epoch : 128 ,weight1 : 0.8817681246130118 ,weight2 : 0.983387747691259,bias : -0.3252343598265885, loss : 0.6000059702936388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 129 ,weight1 : 0.8810315728489372 ,weight2 : 0.9834417068793587,bias : -0.32738365262154134, loss : 0.5994875397780373\n",
      "epoch : 130 ,weight1 : 0.8802975531651502 ,weight2 : 0.9834982446351188,bias : -0.3295277439654222, loss : 0.5989716970068902\n",
      "epoch : 131 ,weight1 : 0.8795660596560178 ,weight2 : 0.9835573548419335,bias : -0.3316666464709833, loss : 0.5984584277302339\n",
      "epoch : 132 ,weight1 : 0.8788370864080216 ,weight2 : 0.9836190313676504,bias : -0.33380037275940516, loss : 0.5979477177510911\n",
      "epoch : 133 ,weight1 : 0.8781106274999869 ,weight2 : 0.9836832680648596,bias : -0.33592893545987457, loss : 0.5974395529256281\n",
      "epoch : 134 ,weight1 : 0.8773866770033091 ,weight2 : 0.9837500587711824,bias : -0.3380523472091656, loss : 0.5969339191633055\n",
      "epoch : 135 ,weight1 : 0.8766652289821792 ,weight2 : 0.9838193973095574,bias : -0.3401706206512234, loss : 0.5964308024270244\n",
      "epoch : 136 ,weight1 : 0.8759462774938083 ,weight2 : 0.9838912774885266,bias : -0.34228376843675085, loss : 0.5959301887332685\n",
      "epoch : 137 ,weight1 : 0.8752298165886495 ,weight2 : 0.9839656931025191,bias : -0.34439180322279855, loss : 0.5954320641522373\n",
      "epoch : 138 ,weight1 : 0.8745158403106198 ,weight2 : 0.9840426379321341,bias : -0.34649473767235744, loss : 0.5949364148079777\n",
      "epoch : 139 ,weight1 : 0.8738043426973195 ,weight2 : 0.9841221057444216,bias : -0.3485925844539546, loss : 0.5944432268785083\n",
      "epoch : 140 ,weight1 : 0.8730953177802513 ,weight2 : 0.9842040902931628,bias : -0.35068535624125163, loss : 0.5939524865959391\n",
      "epoch : 141 ,weight1 : 0.8723887595850363 ,weight2 : 0.9842885853191481,bias : -0.35277306571264677, loss : 0.593464180246587\n",
      "epoch : 142 ,weight1 : 0.8716846621316303 ,weight2 : 0.9843755845504545,bias : -0.3548557255508792, loss : 0.5929782941710845\n",
      "epoch : 143 ,weight1 : 0.8709830194345379 ,weight2 : 0.9844650817027206,bias : -0.35693334844263674, loss : 0.5924948147644836\n",
      "epoch : 144 ,weight1 : 0.8702838255030251 ,weight2 : 0.9845570704794211,bias : -0.35900594707816647, loss : 0.5920137284763574\n",
      "epoch : 145 ,weight1 : 0.8695870743413302 ,weight2 : 0.9846515445721392,bias : -0.3610735341508884, loss : 0.5915350218108935\n",
      "epoch : 146 ,weight1 : 0.8688927599488744 ,weight2 : 0.9847484976608376,bias : -0.3631361223570118, loss : 0.591058681326983\n",
      "epoch : 147 ,weight1 : 0.8682008763204694 ,weight2 : 0.9848479234141284,bias : -0.36519372439515513, loss : 0.5905846936383073\n",
      "epoch : 148 ,weight1 : 0.8675114174465249 ,weight2 : 0.984949815489541,bias : -0.36724635296596825, loss : 0.590113045413417\n",
      "epoch : 149 ,weight1 : 0.866824377313254 ,weight2 : 0.9850541675337885,bias : -0.36929402077175816, loss : 0.5896437233758082\n",
      "epoch : 150 ,weight1 : 0.8661397499028768 ,weight2 : 0.9851609731830334,bias : -0.3713367405161175, loss : 0.5891767143039924\n",
      "epoch : 151 ,weight1 : 0.8654575291938236 ,weight2 : 0.9852702260631507,bias : -0.37337452490355594, loss : 0.5887120050315628\n",
      "epoch : 152 ,weight1 : 0.8647777091609355 ,weight2 : 0.98538191978999,bias : -0.375407386639135, loss : 0.588249582447258\n",
      "epoch : 153 ,weight1 : 0.8641002837756646 ,weight2 : 0.985496047969636,bias : -0.3774353384281051, loss : 0.5877894334950154\n",
      "epoch : 154 ,weight1 : 0.8634252470062717 ,weight2 : 0.9856126041986674,bias : -0.37945839297554657, loss : 0.5873315451740271\n",
      "epoch : 155 ,weight1 : 0.8627525928180231 ,weight2 : 0.9857315820644146,bias : -0.38147656298601257, loss : 0.586875904538786\n",
      "epoch : 156 ,weight1 : 0.8620823151733864 ,weight2 : 0.9858529751452152,bias : -0.383489861163176, loss : 0.5864224986991309\n",
      "epoch : 157 ,weight1 : 0.8614144080322238 ,weight2 : 0.9859767770106683,bias : -0.3854983002094786, loss : 0.5859713148202854\n",
      "epoch : 158 ,weight1 : 0.8607488653519845 ,weight2 : 0.9861029812218876,bias : -0.3875018928257835, loss : 0.5855223401228928\n",
      "epoch : 159 ,weight1 : 0.8600856810878957 ,weight2 : 0.9862315813317516,bias : -0.38950065171103054, loss : 0.5850755618830482\n",
      "epoch : 160 ,weight1 : 0.8594248491931523 ,weight2 : 0.9863625708851542,bias : -0.39149458956189465, loss : 0.5846309674323238\n",
      "epoch : 161 ,weight1 : 0.8587663636191042 ,weight2 : 0.9864959434192521,bias : -0.39348371907244717, loss : 0.5841885441577925\n",
      "epoch : 162 ,weight1 : 0.8581102183154432 ,weight2 : 0.986631692463711,bias : -0.3954680529338201, loss : 0.5837482795020464\n",
      "epoch : 163 ,weight1 : 0.8574564072303883 ,weight2 : 0.9867698115409506,bias : -0.3974476038338732, loss : 0.583310160963211\n",
      "epoch : 164 ,weight1 : 0.8568049243108685 ,weight2 : 0.9869102941663878,bias : -0.39942238445686434, loss : 0.5828741760949564\n",
      "epoch : 165 ,weight1 : 0.8561557635027056 ,weight2 : 0.9870531338486781,bias : -0.40139240748312266, loss : 0.5824403125065027\n",
      "epoch : 166 ,weight1 : 0.8555089187507945 ,weight2 : 0.9871983240899554,bias : -0.4033576855887244, loss : 0.5820085578626241\n",
      "epoch : 167 ,weight1 : 0.8548643839992823 ,weight2 : 0.9873458583860708,bias : -0.40531823144517215, loss : 0.5815788998836471\n",
      "epoch : 168 ,weight1 : 0.8542221531917462 ,weight2 : 0.9874957302268286,bias : -0.40727405771907654, loss : 0.581151326345445\n",
      "epoch : 169 ,weight1 : 0.8535822202713695 ,weight2 : 0.9876479330962218,bias : -0.4092251770718414, loss : 0.5807258250794305\n",
      "epoch : 170 ,weight1 : 0.8529445791811167 ,weight2 : 0.9878024604726656,bias : -0.41117160215935133, loss : 0.5803023839725423\n",
      "epoch : 171 ,weight1 : 0.8523092238639062 ,weight2 : 0.987959305829229,bias : -0.4131133456316624, loss : 0.57988099096723\n",
      "epoch : 172 ,weight1 : 0.8516761482627829 ,weight2 : 0.988118462633865,bias : -0.41505042013269583, loss : 0.579461634061433\n",
      "epoch : 173 ,weight1 : 0.8510453463210883 ,weight2 : 0.9882799243496394,bias : -0.41698283829993443, loss : 0.5790443013085593\n",
      "epoch : 174 ,weight1 : 0.8504168119826291 ,weight2 : 0.9884436844349572,bias : -0.41891061276412206, loss : 0.5786289808174573\n",
      "epoch : 175 ,weight1 : 0.8497905391918451 ,weight2 : 0.9886097363437885,bias : -0.42083375614896584, loss : 0.5782156607523856\n",
      "epoch : 176 ,weight1 : 0.8491665218939752 ,weight2 : 0.9887780735258916,bias : -0.4227522810708413, loss : 0.577804329332981\n",
      "epoch : 177 ,weight1 : 0.8485447540352217 ,weight2 : 0.9889486894270356,bias : -0.42466620013850037, loss : 0.5773949748342193\n",
      "epoch : 178 ,weight1 : 0.8479252295629136 ,weight2 : 0.9891215774892201,bias : -0.4265755259527824, loss : 0.5769875855863773\n",
      "epoch : 179 ,weight1 : 0.8473079424256685 ,weight2 : 0.9892967311508944,bias : -0.4284802711063278, loss : 0.5765821499749878\n",
      "epoch : 180 ,weight1 : 0.8466928865735527 ,weight2 : 0.9894741438471745,bias : -0.4303804481832945, loss : 0.5761786564407924\n",
      "epoch : 181 ,weight1 : 0.8460800559582397 ,weight2 : 0.9896538090100582,bias : -0.4322760697590776, loss : 0.5757770934796936\n",
      "epoch : 182 ,weight1 : 0.8454694445331679 ,weight2 : 0.9898357200686392,bias : -0.43416714840003146, loss : 0.5753774496426992\n",
      "epoch : 183 ,weight1 : 0.8448610462536966 ,weight2 : 0.9900198704493194,bias : -0.43605369666319466, loss : 0.5749797135358685\n",
      "epoch : 184 ,weight1 : 0.8442548550772605 ,weight2 : 0.990206253576019,bias : -0.4379357270960181, loss : 0.5745838738202509\n",
      "epoch : 185 ,weight1 : 0.8436508649635225 ,weight2 : 0.9903948628703856,bias : -0.4398132522360955, loss : 0.574189919211825\n",
      "epoch : 186 ,weight1 : 0.8430490698745257 ,weight2 : 0.9905856917520015,bias : -0.441686284610897, loss : 0.5737978384814324\n",
      "epoch : 187 ,weight1 : 0.8424494637748433 ,weight2 : 0.990778733638589,bias : -0.44355483673750506, loss : 0.573407620454711\n",
      "epoch : 188 ,weight1 : 0.8418520406317279 ,weight2 : 0.9909739819462148,bias : -0.4454189211223538, loss : 0.5730192540120221\n",
      "epoch : 189 ,weight1 : 0.8412567944152586 ,weight2 : 0.9911714300894916,bias : -0.4472785502609707, loss : 0.5726327280883783\n",
      "epoch : 190 ,weight1 : 0.8406637190984867 ,weight2 : 0.9913710714817794,bias : -0.4491337366377209, loss : 0.5722480316733655\n",
      "epoch : 191 ,weight1 : 0.840072808657581 ,weight2 : 0.9915728995353843,bias : -0.4509844927255546, loss : 0.5718651538110641\n",
      "epoch : 192 ,weight1 : 0.8394840570719708 ,weight2 : 0.9917769076617557,bias : -0.452830830985757, loss : 0.5714840835999672\n",
      "epoch : 193 ,weight1 : 0.8388974583244871 ,weight2 : 0.9919830892716825,bias : -0.45467276386770106, loss : 0.5711048101928953\n",
      "epoch : 194 ,weight1 : 0.8383130064015039 ,weight2 : 0.9921914377754869,bias : -0.45651030380860264, loss : 0.5707273227969092\n",
      "epoch : 195 ,weight1 : 0.8377306952930764 ,weight2 : 0.9924019465832167,bias : -0.45834346323327885, loss : 0.57035161067322\n",
      "epoch : 196 ,weight1 : 0.8371505189930796 ,weight2 : 0.9926146091048366,bias : -0.4601722545539087, loss : 0.5699776631370969\n",
      "epoch : 197 ,weight1 : 0.8365724714993434 ,weight2 : 0.9928294187504171,bias : -0.46199669016979644, loss : 0.5696054695577712\n",
      "epoch : 198 ,weight1 : 0.8359965468137888 ,weight2 : 0.9930463689303225,bias : -0.46381678246713787, loss : 0.5692350193583406\n",
      "epoch : 199 ,weight1 : 0.83542273894256 ,weight2 : 0.9932654530553965,bias : -0.4656325438187888, loss : 0.5688663020156678\n",
      "epoch : 200 ,weight1 : 0.8348510418961579 ,weight2 : 0.9934866645371467,bias : -0.46744398658403674, loss : 0.5684993070602794\n",
      "epoch : 201 ,weight1 : 0.8342814496895699 ,weight2 : 0.9937099967879276,bias : -0.4692511231083746, loss : 0.5681340240762605\n",
      "epoch : 202 ,weight1 : 0.8337139563423999 ,weight2 : 0.9939354432211214,bias : -0.4710539657232774, loss : 0.5677704427011482\n",
      "epoch : 203 ,weight1 : 0.8331485558789962 ,weight2 : 0.9941629972513176,bias : -0.47285252674598166, loss : 0.5674085526258235\n",
      "epoch : 204 ,weight1 : 0.8325852423285783 ,weight2 : 0.9943926522944913,bias : -0.47464681847926693, loss : 0.567048343594398\n",
      "epoch : 205 ,weight1 : 0.8320240097253624 ,weight2 : 0.994624401768179,bias : -0.4764368532112403, loss : 0.566689805404103\n",
      "epoch : 206 ,weight1 : 0.8314648521086851 ,weight2 : 0.9948582390916538,bias : -0.4782226432151232, loss : 0.5663329279051715\n",
      "epoch : 207 ,weight1 : 0.8309077635231268 ,weight2 : 0.9950941576860984,bias : -0.4800042007490411, loss : 0.5659777010007219\n",
      "epoch : 208 ,weight1 : 0.8303527380186324 ,weight2 : 0.9953321509747767,bias : -0.4817815380558153, loss : 0.5656241146466379\n",
      "epoch : 209 ,weight1 : 0.829799769650632 ,weight2 : 0.9955722123832034,bias : -0.4835546673627576, loss : 0.5652721588514474\n",
      "epoch : 210 ,weight1 : 0.8292488524801593 ,weight2 : 0.995814335339313,bias : -0.48532360088146725, loss : 0.5649218236761984\n",
      "epoch : 211 ,weight1 : 0.8286999805739695 ,weight2 : 0.9960585132736262,bias : -0.48708835080763063, loss : 0.564573099234332\n",
      "epoch : 212 ,weight1 : 0.828153148004655 ,weight2 : 0.9963047396194152,bias : -0.4888489293208232, loss : 0.5642259756915576\n",
      "epoch : 213 ,weight1 : 0.8276083488507606 ,weight2 : 0.9965530078128677,bias : -0.49060534858431387, loss : 0.5638804432657213\n",
      "epoch : 214 ,weight1 : 0.8270655771968972 ,weight2 : 0.9968033112932485,bias : -0.4923576207448722, loss : 0.5635364922266755\n",
      "epoch : 215 ,weight1 : 0.826524827133854 ,weight2 : 0.9970556435030604,bias : -0.4941057579325777, loss : 0.5631941128961453\n",
      "epoch : 216 ,weight1 : 0.8259860927587093 ,weight2 : 0.9973099978882033,bias : -0.49584977226063154, loss : 0.5628532956475949\n",
      "epoch : 217 ,weight1 : 0.8254493681749407 ,weight2 : 0.9975663678981312,bias : -0.497589675825171, loss : 0.5625140309060895\n",
      "epoch : 218 ,weight1 : 0.8249146474925335 ,weight2 : 0.9978247469860086,bias : -0.4993254807050859, loss : 0.5621763091481592\n",
      "epoch : 219 ,weight1 : 0.8243819248280878 ,weight2 : 0.9980851286088646,bias : -0.501057198961838, loss : 0.5618401209016562\n",
      "epoch : 220 ,weight1 : 0.8238511943049246 ,weight2 : 0.9983475062277457,bias : -0.5027848426392818, loss : 0.5615054567456165\n",
      "epoch : 221 ,weight1 : 0.8233224500531906 ,weight2 : 0.9986118733078674,bias : -0.504508423763489, loss : 0.5611723073101145\n",
      "epoch : 222 ,weight1 : 0.8227956862099618 ,weight2 : 0.9988782233187637,bias : -0.5062279543425744, loss : 0.5608406632761194\n",
      "epoch : 223 ,weight1 : 0.8222708969193454 ,weight2 : 0.9991465497344357,bias : -0.507943446366524, loss : 0.5605105153753489\n",
      "epoch : 224 ,weight1 : 0.8217480763325814 ,weight2 : 0.9994168460334979,bias : -0.5096549118070262, loss : 0.5601818543901226\n",
      "epoch : 225 ,weight1 : 0.8212272186081421 ,weight2 : 0.9996891056993239,bias : -0.5113623626173047, loss : 0.5598546711532102\n",
      "epoch : 226 ,weight1 : 0.8207083179118307 ,weight2 : 0.9999633222201899,bias : -0.5130658107319542, loss : 0.559528956547685\n",
      "epoch : 227 ,weight1 : 0.820191368416879 ,weight2 : 1.000239489089417,bias : -0.5147652680667775, loss : 0.5592047015067679\n",
      "epoch : 228 ,weight1 : 0.8196763643040432 ,weight2 : 1.0005175998055125,bias : -0.5164607465186258, loss : 0.5588818970136775\n",
      "epoch : 229 ,weight1 : 0.8191632997616995 ,weight2 : 1.000797647872308,bias : -0.5181522579652409, loss : 0.5585605341014744\n",
      "epoch : 230 ,weight1 : 0.8186521689859374 ,weight2 : 1.0010796267990985,bias : -0.5198398142650994, loss : 0.5582406038529044\n",
      "epoch : 231 ,weight1 : 0.8181429661806524 ,weight2 : 1.0013635301007782,bias : -0.5215234272572595, loss : 0.557922097400243\n",
      "epoch : 232 ,weight1 : 0.8176356855576379 ,weight2 : 1.0016493512979752,bias : -0.5232031087612098, loss : 0.5576050059251364\n",
      "epoch : 233 ,weight1 : 0.8171303213366752 ,weight2 : 1.0019370839171855,bias : -0.5248788705767201, loss : 0.557289320658442\n",
      "epoch : 234 ,weight1 : 0.8166268677456225 ,weight2 : 1.0022267214909046,bias : -0.526550724483695, loss : 0.556975032880068\n",
      "epoch : 235 ,weight1 : 0.8161253190205034 ,weight2 : 1.002518257557758,bias : -0.5282186822420292, loss : 0.5566621339188117\n",
      "epoch : 236 ,weight1 : 0.8156256694055933 ,weight2 : 1.0028116856626306,bias : -0.5298827555914646, loss : 0.5563506151521956\n",
      "epoch : 237 ,weight1 : 0.8151279131535052 ,weight2 : 1.003106999356794,bias : -0.5315429562514504, loss : 0.5560404680063051\n",
      "epoch : 238 ,weight1 : 0.8146320445252744 ,weight2 : 1.0034041921980335,bias : -0.533199295921005, loss : 0.5557316839556224\n",
      "epoch : 239 ,weight1 : 0.8141380577904418 ,weight2 : 1.0037032577507718,bias : -0.5348517862785793, loss : 0.5554242545228606\n",
      "epoch : 240 ,weight1 : 0.8136459472271365 ,weight2 : 1.0040041895861938,bias : -0.5365004389819231, loss : 0.5551181712787967\n",
      "epoch : 241 ,weight1 : 0.8131557071221566 ,weight2 : 1.0043069812823675,bias : -0.5381452656679532, loss : 0.5548134258421044\n",
      "epoch : 242 ,weight1 : 0.8126673317710497 ,weight2 : 1.0046116264243652,bias : -0.5397862779526232, loss : 0.5545100098791834\n",
      "epoch : 243 ,weight1 : 0.8121808154781915 ,weight2 : 1.0049181186043827,bias : -0.541423487430796, loss : 0.5542079151039916\n",
      "epoch : 244 ,weight1 : 0.8116961525568644 ,weight2 : 1.0052264514218572,bias : -0.5430569056761179, loss : 0.5539071332778736\n",
      "epoch : 245 ,weight1 : 0.8112133373293335 ,weight2 : 1.0055366184835834,bias : -0.5446865442408946, loss : 0.5536076562093885\n",
      "epoch : 246 ,weight1 : 0.8107323641269228 ,weight2 : 1.0058486134038294,bias : -0.5463124146559697, loss : 0.5533094757541384\n",
      "epoch : 247 ,weight1 : 0.81025322729009 ,weight2 : 1.0061624298044496,bias : -0.5479345284306049, loss : 0.5530125838145941\n",
      "epoch : 248 ,weight1 : 0.8097759211684997 ,weight2 : 1.006478061314998,bias : -0.5495528970523619, loss : 0.5527169723399233\n",
      "epoch : 249 ,weight1 : 0.8093004401210966 ,weight2 : 1.0067955015728385,bias : -0.551167531986987, loss : 0.552422633325814\n",
      "epoch : 250 ,weight1 : 0.8088267785161761 ,weight2 : 1.007114744223255,bias : -0.552778444678297, loss : 0.5521295588142995\n",
      "epoch : 251 ,weight1 : 0.8083549307314557 ,weight2 : 1.0074357829195604,bias : -0.5543856465480669, loss : 0.5518377408935824\n",
      "epoch : 252 ,weight1 : 0.8078848911541437 ,weight2 : 1.0077586113232024,bias : -0.5559891489959206, loss : 0.5515471716978577\n",
      "epoch : 253 ,weight1 : 0.8074166541810083 ,weight2 : 1.0080832231038703,bias : -0.557588963399222, loss : 0.5512578434071356\n",
      "epoch : 254 ,weight1 : 0.8069502142184442 ,weight2 : 1.0084096119395989,bias : -0.5591851011129694, loss : 0.5509697482470637\n",
      "epoch : 255 ,weight1 : 0.8064855656825394 ,weight2 : 1.0087377715168722,bias : -0.5607775734696904, loss : 0.5506828784887474\n",
      "epoch : 256 ,weight1 : 0.8060227029991408 ,weight2 : 1.0090676955307247,bias : -0.5623663917793401, loss : 0.550397226448571\n",
      "epoch : 257 ,weight1 : 0.805561620603918 ,weight2 : 1.0093993776848427,bias : -0.5639515673292, loss : 0.5501127844880187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 258 ,weight1 : 0.8051023129424271 ,weight2 : 1.0097328116916626,bias : -0.5655331113837795, loss : 0.5498295450134932\n",
      "epoch : 259 ,weight1 : 0.8046447744701726 ,weight2 : 1.01006799127247,bias : -0.5671110351847183, loss : 0.5495475004761355\n",
      "epoch : 260 ,weight1 : 0.8041889996526694 ,weight2 : 1.0104049101574957,bias : -0.5686853499506918, loss : 0.549266643371643\n",
      "epoch : 261 ,weight1 : 0.8037349829655028 ,weight2 : 1.0107435620860117,bias : -0.5702560668773173, loss : 0.5489869662400884\n",
      "epoch : 262 ,weight1 : 0.8032827188943881 ,weight2 : 1.0110839408064252,bias : -0.5718231971370628, loss : 0.5487084616657365\n",
      "epoch : 263 ,weight1 : 0.8028322019352289 ,weight2 : 1.0114260400763715,bias : -0.5733867518791562, loss : 0.5484311222768632\n",
      "epoch : 264 ,weight1 : 0.8023834265941749 ,weight2 : 1.0117698536628066,bias : -0.5749467422294984, loss : 0.5481549407455701\n",
      "epoch : 265 ,weight1 : 0.8019363873876786 ,weight2 : 1.0121153753420966,bias : -0.5765031792905758, loss : 0.5478799097876034\n",
      "epoch : 266 ,weight1 : 0.8014910788425503 ,weight2 : 1.0124625989001081,bias : -0.5780560741413763, loss : 0.5476060221621681\n",
      "epoch : 267 ,weight1 : 0.8010474954960137 ,weight2 : 1.0128115181322956,bias : -0.5796054378373059, loss : 0.5473332706717454\n",
      "epoch : 268 ,weight1 : 0.8006056318957593 ,weight2 : 1.0131621268437891,bias : -0.5811512814101077, loss : 0.5470616481619072\n",
      "epoch : 269 ,weight1 : 0.800165482599997 ,weight2 : 1.0135144188494793,bias : -0.5826936158677821, loss : 0.5467911475211322\n",
      "epoch : 270 ,weight1 : 0.7997270421775085 ,weight2 : 1.0138683879741024,bias : -0.5842324521945089, loss : 0.5465217616806196\n",
      "epoch : 271 ,weight1 : 0.7992903052076983 ,weight2 : 1.0142240280523236,bias : -0.5857678013505709, loss : 0.5462534836141056\n",
      "epoch : 272 ,weight1 : 0.7988552662806438 ,weight2 : 1.0145813329288194,bias : -0.5872996742722795, loss : 0.5459863063376761\n",
      "epoch : 273 ,weight1 : 0.7984219199971447 ,weight2 : 1.014940296458358,bias : -0.5888280818719012, loss : 0.5457202229095819\n",
      "epoch : 274 ,weight1 : 0.7979902609687712 ,weight2 : 1.0153009125058803,bias : -0.5903530350375866, loss : 0.5454552264300524\n",
      "epoch : 275 ,weight1 : 0.7975602838179118 ,weight2 : 1.0156631749465777,bias : -0.5918745446333005, loss : 0.54519131004111\n",
      "epoch : 276 ,weight1 : 0.7971319831778196 ,weight2 : 1.01602707766597,bias : -0.5933926214987532, loss : 0.5449284669263824\n",
      "epoch : 277 ,weight1 : 0.7967053536926587 ,weight2 : 1.0163926145599822,bias : -0.5949072764493342, loss : 0.5446666903109183\n",
      "epoch : 278 ,weight1 : 0.7962803900175485 ,weight2 : 1.0167597795350198,bias : -0.5964185202760469, loss : 0.5444059734609987\n",
      "epoch : 279 ,weight1 : 0.7958570868186082 ,weight2 : 1.0171285665080425,bias : -0.5979263637454452, loss : 0.544146309683951\n",
      "epoch : 280 ,weight1 : 0.7954354387730002 ,weight2 : 1.017498969406638,bias : -0.5994308175995707, loss : 0.543887692327963\n",
      "epoch : 281 ,weight1 : 0.7950154405689718 ,weight2 : 1.0178709821690939,bias : -0.6009318925558933, loss : 0.5436301147818943\n",
      "epoch : 282 ,weight1 : 0.7945970869058978 ,weight2 : 1.0182445987444682,bias : -0.602429599307251, loss : 0.5433735704750908\n",
      "epoch : 283 ,weight1 : 0.7941803724943206 ,weight2 : 1.0186198130926598,bias : -0.603923948521793, loss : 0.5431180528771965\n",
      "epoch : 284 ,weight1 : 0.7937652920559903 ,weight2 : 1.0189966191844773,bias : -0.605414950842923, loss : 0.5428635554979685\n",
      "epoch : 285 ,weight1 : 0.7933518403239042 ,weight2 : 1.0193750110017057,bias : -0.6069026168892451, loss : 0.5426100718870867\n",
      "epoch : 286 ,weight1 : 0.7929400120423444 ,weight2 : 1.0197549825371743,bias : -0.6083869572545104, loss : 0.54235759563397\n",
      "epoch : 287 ,weight1 : 0.7925298019669165 ,weight2 : 1.020136527794822,bias : -0.609867982507565, loss : 0.5421061203675869\n",
      "epoch : 288 ,weight1 : 0.7921212048645853 ,weight2 : 1.0205196407897612,bias : -0.6113457031922999, loss : 0.5418556397562695\n",
      "epoch : 289 ,weight1 : 0.7917142155137114 ,weight2 : 1.0209043155483422,bias : -0.6128201298276016, loss : 0.5416061475075272\n",
      "epoch : 290 ,weight1 : 0.7913088287040863 ,weight2 : 1.0212905461082151,bias : -0.6142912729073051, loss : 0.5413576373678578\n",
      "epoch : 291 ,weight1 : 0.790905039236967 ,weight2 : 1.0216783265183917,bias : -0.6157591429001473, loss : 0.5411101031225622\n",
      "epoch : 292 ,weight1 : 0.7905028419251093 ,weight2 : 1.0220676508393058,bias : -0.6172237502497224, loss : 0.5408635385955579\n",
      "epoch : 293 ,weight1 : 0.7901022315928014 ,weight2 : 1.0224585131428723,bias : -0.6186851053744382, loss : 0.5406179376491905\n",
      "epoch : 294 ,weight1 : 0.7897032030758954 ,weight2 : 1.0228509075125463,bias : -0.6201432186674742, loss : 0.5403732941840493\n",
      "epoch : 295 ,weight1 : 0.7893057512218393 ,weight2 : 1.02324482804338,bias : -0.6215981004967406, loss : 0.540129602138779\n",
      "epoch : 296 ,weight1 : 0.7889098708897075 ,weight2 : 1.0236402688420794,bias : -0.6230497612048387, loss : 0.5398868554898952\n",
      "epoch : 297 ,weight1 : 0.788515556950231 ,weight2 : 1.0240372240270603,bias : -0.6244982111090231, loss : 0.5396450482515963\n",
      "epoch : 298 ,weight1 : 0.7881228042858263 ,weight2 : 1.024435687728502,bias : -0.6259434605011648, loss : 0.5394041744755796\n",
      "epoch : 299 ,weight1 : 0.7877316077906242 ,weight2 : 1.0248356540884012,bias : -0.6273855196477148, loss : 0.5391642282508537\n",
      "epoch : 300 ,weight1 : 0.7873419623704981 ,weight2 : 1.025237117260625,bias : -0.6288243987896708, loss : 0.5389252037035536\n",
      "epoch : 301 ,weight1 : 0.7869538629430904 ,weight2 : 1.025640071410962,bias : -0.6302601081425433, loss : 0.5386870949967558\n",
      "epoch : 302 ,weight1 : 0.7865673044378395 ,weight2 : 1.0260445107171732,bias : -0.6316926578963242, loss : 0.5384498963302926\n",
      "epoch : 303 ,weight1 : 0.7861822817960052 ,weight2 : 1.0264504293690424,bias : -0.6331220582154561, loss : 0.5382136019405668\n",
      "epoch : 304 ,weight1 : 0.7857987899706943 ,weight2 : 1.0268578215684243,bias : -0.6345483192388025, loss : 0.5379782061003674\n",
      "epoch : 305 ,weight1 : 0.7854168239268844 ,weight2 : 1.0272666815292926,bias : -0.63597145107962, loss : 0.5377437031186855\n",
      "epoch : 306 ,weight1 : 0.7850363786414483 ,weight2 : 1.0276770034777876,bias : -0.6373914638255314, loss : 0.5375100873405291\n",
      "epoch : 307 ,weight1 : 0.7846574491031766 ,weight2 : 1.0280887816522617,bias : -0.6388083675384991, loss : 0.5372773531467397\n",
      "epoch : 308 ,weight1 : 0.7842800303128005 ,weight2 : 1.0285020103033253,bias : -0.6402221722548015, loss : 0.5370454949538095\n",
      "epoch : 309 ,weight1 : 0.7839041172830132 ,weight2 : 1.0289166836938908,bias : -0.6416328879850085, loss : 0.5368145072136956\n",
      "epoch : 310 ,weight1 : 0.7835297050384915 ,weight2 : 1.029332796099216,bias : -0.6430405247139597, loss : 0.5365843844136396\n",
      "epoch : 311 ,weight1 : 0.7831567886159158 ,weight2 : 1.0297503418069471,bias : -0.644445092400743, loss : 0.5363551210759833\n",
      "epoch : 312 ,weight1 : 0.7827853630639902 ,weight2 : 1.0301693151171603,bias : -0.6458466009786744, loss : 0.5361267117579864\n",
      "epoch : 313 ,weight1 : 0.7824154234434619 ,weight2 : 1.0305897103424024,bias : -0.6472450603552793, loss : 0.535899151051645\n",
      "epoch : 314 ,weight1 : 0.7820469648271398 ,weight2 : 1.0310115218077318,bias : -0.6486404804122741, loss : 0.5356724335835089\n",
      "epoch : 315 ,weight1 : 0.781679982299912 ,weight2 : 1.0314347438507565,bias : -0.6500328710055496, loss : 0.5354465540145013\n",
      "epoch : 316 ,weight1 : 0.7813144709587638 ,weight2 : 1.0318593708216734,bias : -0.6514222419651557, loss : 0.5352215070397363\n",
      "epoch : 317 ,weight1 : 0.7809504259127944 ,weight2 : 1.0322853970833057,bias : -0.6528086030952859, loss : 0.5349972873883395\n",
      "epoch : 318 ,weight1 : 0.7805878422832327 ,weight2 : 1.0327128170111393,bias : -0.6541919641742642, loss : 0.5347738898232672\n",
      "epoch : 319 ,weight1 : 0.7802267152034535 ,weight2 : 1.033141624993359,bias : -0.6555723349545323, loss : 0.5345513091411265\n",
      "epoch : 320 ,weight1 : 0.779867039818992 ,weight2 : 1.0335718154308835,bias : -0.6569497251626382, loss : 0.534329540171995\n",
      "epoch : 321 ,weight1 : 0.7795088112875583 ,weight2 : 1.0340033827374002,bias : -0.6583241444992255, loss : 0.5341085777792428\n",
      "epoch : 322 ,weight1 : 0.7791520247790518 ,weight2 : 1.0344363213393981,bias : -0.659695602639024, loss : 0.5338884168593537\n",
      "epoch : 323 ,weight1 : 0.7787966754755737 ,weight2 : 1.0348706256762006,bias : -0.6610641092308412, loss : 0.5336690523417458\n",
      "epoch : 324 ,weight1 : 0.7784427585714405 ,weight2 : 1.035306290199998,bias : -0.6624296738975545, loss : 0.5334504791885941\n",
      "epoch : 325 ,weight1 : 0.7780902692731957 ,weight2 : 1.0357433093758783,bias : -0.6637923062361045, loss : 0.5332326923946537\n",
      "epoch : 326 ,weight1 : 0.7777392027996216 ,weight2 : 1.0361816776818578,bias : -0.6651520158174903, loss : 0.5330156869870821\n",
      "epoch : 327 ,weight1 : 0.7773895543817503 ,weight2 : 1.0366213896089105,bias : -0.6665088121867636, loss : 0.5327994580252627\n",
      "epoch : 328 ,weight1 : 0.7770413192628743 ,weight2 : 1.0370624396609975,bias : -0.6678627048630259, loss : 0.5325840006006287\n",
      "epoch : 329 ,weight1 : 0.7766944926985568 ,weight2 : 1.037504822355095,bias : -0.6692137033394253, loss : 0.5323693098364878\n",
      "epoch : 330 ,weight1 : 0.7763490699566405 ,weight2 : 1.0379485322212212,bias : -0.6705618170831549, loss : 0.5321553808878462\n",
      "epoch : 331 ,weight1 : 0.7760050463172573 ,weight2 : 1.0383935638024642,bias : -0.6719070555354515, loss : 0.5319422089412348\n",
      "epoch : 332 ,weight1 : 0.7756624170728362 ,weight2 : 1.0388399116550069,bias : -0.6732494281115959, loss : 0.5317297892145343\n",
      "epoch : 333 ,weight1 : 0.7753211775281117 ,weight2 : 1.039287570348153,bias : -0.6745889442009138, loss : 0.5315181169568017\n",
      "epoch : 334 ,weight1 : 0.7749813230001308 ,weight2 : 1.039736534464351,bias : -0.6759256131667768, loss : 0.5313071874480972\n",
      "epoch : 335 ,weight1 : 0.7746428488182601 ,weight2 : 1.0401867985992186,bias : -0.6772594443466061, loss : 0.5310969959993106\n",
      "epoch : 336 ,weight1 : 0.7743057503241922 ,weight2 : 1.0406383573615656,bias : -0.6785904470518753, loss : 0.5308875379519908\n",
      "epoch : 337 ,weight1 : 0.773970022871952 ,weight2 : 1.0410912053734167,bias : -0.6799186305681147, loss : 0.5306788086781722\n",
      "epoch : 338 ,weight1 : 0.7736356618279014 ,weight2 : 1.0415453372700327,bias : -0.6812440041549167, loss : 0.5304708035802042\n",
      "epoch : 339 ,weight1 : 0.7733026625707451 ,weight2 : 1.0420007476999322,bias : -0.6825665770459416, loss : 0.5302635180905807\n",
      "epoch : 340 ,weight1 : 0.7729710204915343 ,weight2 : 1.042457431324912,bias : -0.6838863584489246, loss : 0.5300569476717701\n",
      "epoch : 341 ,weight1 : 0.7726407309936716 ,weight2 : 1.0429153828200664,bias : -0.6852033575456834, loss : 0.5298510878160447\n",
      "epoch : 342 ,weight1 : 0.7723117894929137 ,weight2 : 1.0433745968738068,bias : -0.6865175834921262, loss : 0.5296459340453125\n",
      "epoch : 343 ,weight1 : 0.7719841914173751 ,weight2 : 1.0438350681878805,bias : -0.6878290454182617, loss : 0.5294414819109486\n",
      "epoch : 344 ,weight1 : 0.7716579322075304 ,weight2 : 1.0442967914773877,bias : -0.6891377524282086, loss : 0.5292377269936263\n",
      "epoch : 345 ,weight1 : 0.7713330073162169 ,weight2 : 1.0447597614707995,bias : -0.6904437136002063, loss : 0.5290346649031507\n",
      "epoch : 346 ,weight1 : 0.7710094122086358 ,weight2 : 1.045223972909974,bias : -0.6917469379866267, loss : 0.5288322912782913\n",
      "epoch : 347 ,weight1 : 0.7706871423623542 ,weight2 : 1.045689420550172,bias : -0.6930474346139864, loss : 0.5286306017866156\n",
      "epoch : 348 ,weight1 : 0.7703661932673054 ,weight2 : 1.0461560991600738,bias : -0.69434521248296, loss : 0.5284295921243234\n",
      "epoch : 349 ,weight1 : 0.7700465604257893 ,weight2 : 1.0466240035217917,bias : -0.6956402805683933, loss : 0.5282292580160817\n",
      "epoch : 350 ,weight1 : 0.7697282393524731 ,weight2 : 1.047093128430886,bias : -0.6969326478193184, loss : 0.5280295952148601\n",
      "epoch : 351 ,weight1 : 0.7694112255743903 ,weight2 : 1.0475634686963775,bias : -0.6982223231589686, loss : 0.527830599501766\n",
      "epoch : 352 ,weight1 : 0.7690955146309402 ,weight2 : 1.0480350191407608,bias : -0.6995093154847944, loss : 0.5276322666858829\n",
      "epoch : 353 ,weight1 : 0.7687811020738863 ,weight2 : 1.0485077746000164,bias : -0.7007936336684805, loss : 0.5274345926041049\n",
      "epoch : 354 ,weight1 : 0.7684679834673552 ,weight2 : 1.0489817299236228,bias : -0.7020752865559625, loss : 0.5272375731209767\n",
      "epoch : 355 ,weight1 : 0.7681561543878344 ,weight2 : 1.0494568799745674,bias : -0.7033542829674455, loss : 0.5270412041285312\n",
      "epoch : 356 ,weight1 : 0.7678456104241692 ,weight2 : 1.0499332196293572,bias : -0.7046306316974225, loss : 0.5268454815461273\n",
      "epoch : 357 ,weight1 : 0.7675363471775611 ,weight2 : 1.0504107437780286,bias : -0.7059043415146937, loss : 0.526650401320291\n",
      "epoch : 358 ,weight1 : 0.7672283602615638 ,weight2 : 1.0508894473241575,bias : -0.707175421162387, loss : 0.5264559594245543\n",
      "epoch : 359 ,weight1 : 0.7669216453020796 ,weight2 : 1.0513693251848673,bias : -0.7084438793579779, loss : 0.526262151859297\n",
      "epoch : 360 ,weight1 : 0.7666161979373558 ,weight2 : 1.051850372290838,bias : -0.7097097247933117, loss : 0.5260689746515866\n",
      "epoch : 361 ,weight1 : 0.7663120138179801 ,weight2 : 1.0523325835863144,bias : -0.7109729661346249, loss : 0.525876423855021\n",
      "epoch : 362 ,weight1 : 0.7660090886068759 ,weight2 : 1.0528159540291118,bias : -0.7122336120225676, loss : 0.5256844955495715\n",
      "epoch : 363 ,weight1 : 0.7657074179792974 ,weight2 : 1.0533004785906244,bias : -0.7134916710722274, loss : 0.5254931858414246\n",
      "epoch : 364 ,weight1 : 0.7654069976228243 ,weight2 : 1.053786152255831,bias : -0.7147471518731526, loss : 0.5253024908628271\n",
      "epoch : 365 ,weight1 : 0.7651078232373553 ,weight2 : 1.0542729700233004,bias : -0.7160000629893768, loss : 0.5251124067719297\n",
      "epoch : 366 ,weight1 : 0.7648098905351027 ,weight2 : 1.0547609269051972,bias : -0.7172504129594438, loss : 0.5249229297526317\n",
      "epoch : 367 ,weight1 : 0.7645131952405857 ,weight2 : 1.055250017927286,bias : -0.7184982102964336, loss : 0.5247340560144282\n",
      "epoch : 368 ,weight1 : 0.7642177330906235 ,weight2 : 1.0557402381289356,bias : -0.719743463487988, loss : 0.5245457817922539\n",
      "epoch : 369 ,weight1 : 0.763923499834328 ,weight2 : 1.0562315825631232,bias : -0.7209861809963376, loss : 0.5243581033463323\n",
      "epoch : 370 ,weight1 : 0.7636304912330966 ,weight2 : 1.0567240462964373,bias : -0.7222263712583291, loss : 0.5241710169620216\n",
      "epoch : 371 ,weight1 : 0.7633387030606041 ,weight2 : 1.0572176244090803,bias : -0.7234640426854533, loss : 0.5239845189496638\n",
      "epoch : 372 ,weight1 : 0.763048131102795 ,weight2 : 1.057712311994871,bias : -0.7246992036638729, loss : 0.5237986056444329\n",
      "epoch : 373 ,weight1 : 0.7627587711578742 ,weight2 : 1.0582081041612463,bias : -0.7259318625544521, loss : 0.5236132734061845\n",
      "epoch : 374 ,weight1 : 0.7624706190362986 ,weight2 : 1.0587049960292623,bias : -0.7271620276927857, loss : 0.5234285186193063\n",
      "epoch : 375 ,weight1 : 0.7621836705607687 ,weight2 : 1.0592029827335954,bias : -0.7283897073892294, loss : 0.5232443376925674\n",
      "epoch : 376 ,weight1 : 0.7618979215662179 ,weight2 : 1.0597020594225428,bias : -0.7296149099289297, loss : 0.5230607270589716\n",
      "epoch : 377 ,weight1 : 0.7616133678998036 ,weight2 : 1.0602022212580218,bias : -0.7308376435718558, loss : 0.5228776831756073\n",
      "epoch : 378 ,weight1 : 0.7613300054208969 ,weight2 : 1.06070346341557,bias : -0.7320579165528301, loss : 0.5226952025235024\n",
      "epoch : 379 ,weight1 : 0.7610478300010723 ,weight2 : 1.061205781084344,bias : -0.7332757370815611, loss : 0.522513281607475\n",
      "epoch : 380 ,weight1 : 0.7607668375240972 ,weight2 : 1.0617091694671177,bias : -0.7344911133426753, loss : 0.5223319169559894\n",
      "epoch : 381 ,weight1 : 0.7604870238859208 ,weight2 : 1.0622136237802808,bias : -0.7357040534957503, loss : 0.5221511051210096\n",
      "epoch : 382 ,weight1 : 0.7602083849946628 ,weight2 : 1.062719139253837,bias : -0.7369145656753487, loss : 0.5219708426778544\n",
      "epoch : 383 ,weight1 : 0.7599309167706022 ,weight2 : 1.0632257111314003,bias : -0.7381226579910515, loss : 0.5217911262250545\n",
      "epoch : 384 ,weight1 : 0.7596546151461655 ,weight2 : 1.0637333346701923,bias : -0.7393283385274925, loss : 0.5216119523842069\n",
      "epoch : 385 ,weight1 : 0.7593794760659143 ,weight2 : 1.0642420051410388,bias : -0.7405316153443934, loss : 0.5214333177998339\n",
      "epoch : 386 ,weight1 : 0.7591054954865333 ,weight2 : 1.0647517178283663,bias : -0.7417324964765989, loss : 0.5212552191392401\n",
      "epoch : 387 ,weight1 : 0.7588326693768176 ,weight2 : 1.0652624680301963,bias : -0.7429309899341126, loss : 0.521077653092371\n",
      "epoch : 388 ,weight1 : 0.7585609937176601 ,weight2 : 1.0657742510581418,bias : -0.7441271037021328, loss : 0.5209006163716714\n",
      "epoch : 389 ,weight1 : 0.7582904645020379 ,weight2 : 1.066287062237402,bias : -0.7453208457410895, loss : 0.5207241057119467\n",
      "epoch : 390 ,weight1 : 0.7580210777349994 ,weight2 : 1.0668008969067562,bias : -0.746512223986681, loss : 0.5205481178702219\n",
      "epoch : 391 ,weight1 : 0.7577528294336503 ,weight2 : 1.067315750418558,bias : -0.7477012463499119, loss : 0.520372649625603\n",
      "epoch : 392 ,weight1 : 0.7574857156271401 ,weight2 : 1.0678316181387295,bias : -0.74888792071713, loss : 0.5201976977791393\n",
      "epoch : 393 ,weight1 : 0.7572197323566474 ,weight2 : 1.0683484954467541,bias : -0.7500722549500652, loss : 0.5200232591536847\n",
      "epoch : 394 ,weight1 : 0.7569548756753665 ,weight2 : 1.06886637773567,bias : -0.7512542568858684, loss : 0.5198493305937617\n",
      "epoch : 395 ,weight1 : 0.7566911416484915 ,weight2 : 1.069385260412062,bias : -0.7524339343371496, loss : 0.5196759089654247\n",
      "epoch : 396 ,weight1 : 0.7564285263532028 ,weight2 : 1.0699051388960543,bias : -0.7536112950920176, loss : 0.5195029911561236\n",
      "epoch : 397 ,weight1 : 0.756167025878651 ,weight2 : 1.0704260086213024,bias : -0.7547863469141205, loss : 0.5193305740745704\n",
      "epoch : 398 ,weight1 : 0.7559066363259421 ,weight2 : 1.0709478650349842,bias : -0.7559590975426848, loss : 0.5191586546506037\n",
      "epoch : 399 ,weight1 : 0.7556473538081219 ,weight2 : 1.0714707035977913,bias : -0.7571295546925564, loss : 0.5189872298350544\n",
      "epoch : 400 ,weight1 : 0.75538917445016 ,weight2 : 1.0719945197839198,bias : -0.7582977260542415, loss : 0.5188162965996145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 401 ,weight1 : 0.755132094388934 ,weight2 : 1.0725193090810612,bias : -0.7594636192939477, loss : 0.5186458519367024\n",
      "epoch : 402 ,weight1 : 0.7548761097732136 ,weight2 : 1.073045066990392,bias : -0.7606272420536253, loss : 0.5184758928593333\n",
      "epoch : 403 ,weight1 : 0.7546212167636437 ,weight2 : 1.0735717890265633,bias : -0.76178860195101, loss : 0.5183064164009866\n",
      "epoch : 404 ,weight1 : 0.7543674115327278 ,weight2 : 1.074099470717691,bias : -0.7629477065796638, loss : 0.518137419615476\n",
      "epoch : 405 ,weight1 : 0.7541146902648117 ,weight2 : 1.0746281076053443,bias : -0.7641045635090191, loss : 0.51796889957682\n",
      "epoch : 406 ,weight1 : 0.753863049156066 ,weight2 : 1.0751576952445352,bias : -0.7652591802844204, loss : 0.5178008533791114\n",
      "epoch : 407 ,weight1 : 0.7536124844144688 ,weight2 : 1.0756882292037062,bias : -0.7664115644271681, loss : 0.5176332781363909\n",
      "epoch : 408 ,weight1 : 0.7533629922597888 ,weight2 : 1.0762197050647189,bias : -0.7675617234345615, loss : 0.5174661709825177\n",
      "epoch : 409 ,weight1 : 0.7531145689235669 ,weight2 : 1.076752118422842,bias : -0.7687096647799435, loss : 0.5172995290710424\n",
      "epoch : 410 ,weight1 : 0.7528672106490991 ,weight2 : 1.0772854648867383,bias : -0.7698553959127438, loss : 0.517133349575081\n",
      "epoch : 411 ,weight1 : 0.7526209136914183 ,weight2 : 1.077819740078453,bias : -0.7709989242585237, loss : 0.5169676296871887\n",
      "epoch : 412 ,weight1 : 0.7523756743172756 ,weight2 : 1.0783549396334,bias : -0.7721402572190209, loss : 0.5168023666192343\n",
      "epoch : 413 ,weight1 : 0.7521314888051227 ,weight2 : 1.0788910592003484,bias : -0.7732794021721946, loss : 0.5166375576022767\n",
      "epoch : 414 ,weight1 : 0.7518883534450927 ,weight2 : 1.0794280944414094,bias : -0.7744163664722703, loss : 0.5164731998864397\n",
      "epoch : 415 ,weight1 : 0.7516462645389819 ,weight2 : 1.0799660410320218,bias : -0.7755511574497858, loss : 0.5163092907407889\n",
      "epoch : 416 ,weight1 : 0.7514052184002302 ,weight2 : 1.0805048946609388,bias : -0.7766837824116367, loss : 0.5161458274532091\n",
      "epoch : 417 ,weight1 : 0.7511652113539029 ,weight2 : 1.0810446510302125,bias : -0.777814248641123, loss : 0.5159828073302833\n",
      "epoch : 418 ,weight1 : 0.7509262397366706 ,weight2 : 1.08158530585518,bias : -0.7789425633979948, loss : 0.5158202276971694\n",
      "epoch : 419 ,weight1 : 0.7506882998967903 ,weight2 : 1.0821268548644483,bias : -0.7800687339184994, loss : 0.5156580858974807\n",
      "epoch : 420 ,weight1 : 0.7504513881940856 ,weight2 : 1.082669293799878,bias : -0.7811927674154279, loss : 0.5154963792931659\n",
      "epoch : 421 ,weight1 : 0.7502155009999271 ,weight2 : 1.0832126184165696,bias : -0.7823146710781624, loss : 0.5153351052643883\n",
      "epoch : 422 ,weight1 : 0.7499806346972122 ,weight2 : 1.083756824482846,bias : -0.7834344520727234, loss : 0.5151742612094082\n",
      "epoch : 423 ,weight1 : 0.7497467856803456 ,weight2 : 1.0843019077802374,bias : -0.7845521175418173, loss : 0.5150138445444645\n",
      "epoch : 424 ,weight1 : 0.7495139503552184 ,weight2 : 1.0848478641034651,bias : -0.7856676746048842, loss : 0.5148538527036569\n",
      "epoch : 425 ,weight1 : 0.7492821251391882 ,weight2 : 1.0853946892604247,bias : -0.7867811303581459, loss : 0.5146942831388286\n",
      "epoch : 426 ,weight1 : 0.7490513064610586 ,weight2 : 1.0859423790721692,bias : -0.7878924918746545, loss : 0.5145351333194503\n",
      "epoch : 427 ,weight1 : 0.748821490761058 ,weight2 : 1.0864909293728922,bias : -0.7890017662043403, loss : 0.5143764007325049\n",
      "epoch : 428 ,weight1 : 0.7485926744908196 ,weight2 : 1.0870403360099103,bias : -0.790108960374061, loss : 0.5142180828823714\n",
      "epoch : 429 ,weight1 : 0.7483648541133597 ,weight2 : 1.0875905948436464,bias : -0.7912140813876505, loss : 0.5140601772907116\n",
      "epoch : 430 ,weight1 : 0.7481380261030574 ,weight2 : 1.0881417017476112,bias : -0.7923171362259678, loss : 0.5139026814963558\n",
      "epoch : 431 ,weight1 : 0.7479121869456323 ,weight2 : 1.0886936526083855,bias : -0.7934181318469464, loss : 0.5137455930551894\n",
      "epoch : 432 ,weight1 : 0.7476873331381245 ,weight2 : 1.089246443325602,bias : -0.7945170751856441, loss : 0.5135889095400403\n",
      "epoch : 433 ,weight1 : 0.747463461188872 ,weight2 : 1.0898000698119272,bias : -0.7956139731542922, loss : 0.5134326285405676\n",
      "epoch : 434 ,weight1 : 0.7472405676174895 ,weight2 : 1.0903545279930427,bias : -0.7967088326423457, loss : 0.5132767476631492\n",
      "epoch : 435 ,weight1 : 0.7470186489548468 ,weight2 : 1.0909098138076259,bias : -0.7978016605165336, loss : 0.5131212645307724\n",
      "epoch : 436 ,weight1 : 0.7467977017430469 ,weight2 : 1.0914659232073314,bias : -0.7988924636209084, loss : 0.5129661767829227\n",
      "epoch : 437 ,weight1 : 0.7465777225354038 ,weight2 : 1.0920228521567716,bias : -0.7999812487768972, loss : 0.5128114820754747\n",
      "epoch : 438 ,weight1 : 0.7463587078964204 ,weight2 : 1.0925805966334978,bias : -0.8010680227833523, loss : 0.5126571780805833\n",
      "epoch : 439 ,weight1 : 0.7461406544017668 ,weight2 : 1.0931391526279797,bias : -0.8021527924166013, loss : 0.5125032624865757\n",
      "epoch : 440 ,weight1 : 0.7459235586382572 ,weight2 : 1.093698516143586,bias : -0.8032355644304988, loss : 0.5123497329978429\n",
      "epoch : 441 ,weight1 : 0.7457074172038279 ,weight2 : 1.0942586831965644,bias : -0.804316345556477, loss : 0.5121965873347334\n",
      "epoch : 442 ,weight1 : 0.745492226707515 ,weight2 : 1.0948196498160212,bias : -0.8053951425035971, loss : 0.5120438232334467\n",
      "epoch : 443 ,weight1 : 0.7452779837694311 ,weight2 : 1.095381412043901,bias : -0.8064719619586007, loss : 0.5118914384459268\n",
      "epoch : 444 ,weight1 : 0.745064685020743 ,weight2 : 1.0959439659349657,bias : -0.8075468105859614, loss : 0.5117394307397582\n",
      "epoch : 445 ,weight1 : 0.7448523271036486 ,weight2 : 1.0965073075567746,bias : -0.8086196950279364, loss : 0.5115877978980599\n",
      "epoch : 446 ,weight1 : 0.744640906671354 ,weight2 : 1.0970714329896627,bias : -0.8096906219046182, loss : 0.5114365377193825\n",
      "epoch : 447 ,weight1 : 0.7444304203880506 ,weight2 : 1.0976363383267196,bias : -0.8107595978139867, loss : 0.5112856480176035\n",
      "epoch : 448 ,weight1 : 0.7442208649288917 ,weight2 : 1.0982020196737683,bias : -0.8118266293319614, loss : 0.5111351266218261\n",
      "epoch : 449 ,weight1 : 0.7440122369799693 ,weight2 : 1.0987684731493437,bias : -0.8128917230124534, loss : 0.5109849713762753\n",
      "epoch : 450 ,weight1 : 0.7438045332382907 ,weight2 : 1.0993356948846709,bias : -0.8139548853874178, loss : 0.5108351801401977\n",
      "epoch : 451 ,weight1 : 0.743597750411755 ,weight2 : 1.0999036810236436,bias : -0.8150161229669064, loss : 0.5106857507877589\n",
      "epoch : 452 ,weight1 : 0.74339188521913 ,weight2 : 1.1004724277228015,bias : -0.8160754422391199, loss : 0.5105366812079442\n",
      "epoch : 453 ,weight1 : 0.7431869343900279 ,weight2 : 1.101041931151309,bias : -0.817132849670461, loss : 0.5103879693044587\n",
      "epoch : 454 ,weight1 : 0.7429828946648821 ,weight2 : 1.1016121874909321,bias : -0.8181883517055867, loss : 0.5102396129956268\n",
      "epoch : 455 ,weight1 : 0.7427797627949232 ,weight2 : 1.1021831929360164,bias : -0.819241954767462, loss : 0.5100916102142946\n",
      "epoch : 456 ,weight1 : 0.742577535542155 ,weight2 : 1.102754943693464,bias : -0.820293665257412, loss : 0.5099439589077318\n",
      "epoch : 457 ,weight1 : 0.7423762096793309 ,weight2 : 1.1033274359827117,bias : -0.8213434895551759, loss : 0.5097966570375331\n",
      "epoch : 458 ,weight1 : 0.7421757819899295 ,weight2 : 1.1039006660357065,bias : -0.8223914340189595, loss : 0.5096497025795219\n",
      "epoch : 459 ,weight1 : 0.7419762492681307 ,weight2 : 1.104474630096884,bias : -0.8234375049854892, loss : 0.509503093523654\n",
      "epoch : 460 ,weight1 : 0.7417776083187914 ,weight2 : 1.1050493244231445,bias : -0.8244817087700647, loss : 0.5093568278739209\n",
      "epoch : 461 ,weight1 : 0.7415798559574214 ,weight2 : 1.1056247452838301,bias : -0.825524051666613, loss : 0.5092109036482558\n",
      "epoch : 462 ,weight1 : 0.7413829890101589 ,weight2 : 1.1062008889607002,bias : -0.826564539947742, loss : 0.5090653188784376\n",
      "epoch : 463 ,weight1 : 0.7411870043137462 ,weight2 : 1.1067777517479092,bias : -0.827603179864794, loss : 0.5089200716099975\n",
      "epoch : 464 ,weight1 : 0.7409918987155052 ,weight2 : 1.1073553299519816,bias : -0.8286399776478993, loss : 0.5087751599021247\n",
      "epoch : 465 ,weight1 : 0.7407976690733128 ,weight2 : 1.107933619891789,bias : -0.8296749395060304, loss : 0.5086305818275746\n",
      "epoch : 466 ,weight1 : 0.7406043122555764 ,weight2 : 1.1085126178985254,bias : -0.8307080716270557, loss : 0.5084863354725748\n",
      "epoch : 467 ,weight1 : 0.7404118251412095 ,weight2 : 1.1090923203156835,bias : -0.8317393801777935, loss : 0.508342418936734\n",
      "epoch : 468 ,weight1 : 0.7402202046196062 ,weight2 : 1.1096727234990302,bias : -0.8327688713040658, loss : 0.5081988303329503\n",
      "epoch : 469 ,weight1 : 0.7400294475906175 ,weight2 : 1.1102538238165822,bias : -0.8337965511307531, loss : 0.508055567787321\n",
      "epoch : 470 ,weight1 : 0.7398395509645255 ,weight2 : 1.1108356176485819,bias : -0.8348224257618478, loss : 0.5079126294390516\n",
      "epoch : 471 ,weight1 : 0.7396505116620189 ,weight2 : 1.111418101387472,bias : -0.8358465012805087, loss : 0.5077700134403658\n",
      "epoch : 472 ,weight1 : 0.7394623266141683 ,weight2 : 1.1120012714378718,bias : -0.8368687837491157, loss : 0.5076277179564179\n",
      "epoch : 473 ,weight1 : 0.739274992762401 ,weight2 : 1.1125851242165512,bias : -0.8378892792093232, loss : 0.5074857411652017\n",
      "epoch : 474 ,weight1 : 0.7390885070584757 ,weight2 : 1.113169656152407,bias : -0.8389079936821157, loss : 0.5073440812574649\n",
      "epoch : 475 ,weight1 : 0.7389028664644578 ,weight2 : 1.1137548636864363,bias : -0.839924933167861, loss : 0.5072027364366195\n",
      "epoch : 476 ,weight1 : 0.7387180679526941 ,weight2 : 1.114340743271713,bias : -0.8409401036463657, loss : 0.5070617049186559\n",
      "epoch : 477 ,weight1 : 0.7385341085057876 ,weight2 : 1.114927291373361,bias : -0.8419535110769293, loss : 0.5069209849320565\n",
      "epoch : 478 ,weight1 : 0.7383509851165722 ,weight2 : 1.1155145044685304,bias : -0.8429651613983984, loss : 0.5067805747177082\n",
      "epoch : 479 ,weight1 : 0.7381686947880874 ,weight2 : 1.1161023790463704,bias : -0.8439750605292221, loss : 0.5066404725288194\n",
      "epoch : 480 ,weight1 : 0.7379872345335536 ,weight2 : 1.116690911608005,bias : -0.8449832143675061, loss : 0.5065006766308325\n",
      "epoch : 481 ,weight1 : 0.7378066013763458 ,weight2 : 1.1172800986665068,bias : -0.8459896287910675, loss : 0.5063611853013418\n",
      "epoch : 482 ,weight1 : 0.7376267923499686 ,weight2 : 1.117869936746871,bias : -0.8469943096574897, loss : 0.5062219968300076\n",
      "epoch : 483 ,weight1 : 0.737447804498031 ,weight2 : 1.11846042238599,bias : -0.8479972628041764, loss : 0.506083109518474\n",
      "epoch : 484 ,weight1 : 0.7372696348742207 ,weight2 : 1.1190515521326274,bias : -0.8489984940484075, loss : 0.5059445216802864\n",
      "epoch : 485 ,weight1 : 0.7370922805422786 ,weight2 : 1.1196433225473919,bias : -0.8499980091873931, loss : 0.5058062316408082\n",
      "epoch : 486 ,weight1 : 0.7369157385759734 ,weight2 : 1.120235730202711,bias : -0.8509958139983285, loss : 0.5056682377371391\n",
      "epoch : 487 ,weight1 : 0.7367400060590756 ,weight2 : 1.1208287716828056,bias : -0.8519919142384488, loss : 0.5055305383180341\n",
      "epoch : 488 ,weight1 : 0.7365650800853327 ,weight2 : 1.1214224435836624,bias : -0.8529863156450843, loss : 0.5053931317438236\n",
      "epoch : 489 ,weight1 : 0.7363909577584428 ,weight2 : 1.1220167425130085,bias : -0.853979023935715, loss : 0.5052560163863306\n",
      "epoch : 490 ,weight1 : 0.7362176361920292 ,weight2 : 1.1226116650902853,bias : -0.8549700448080253, loss : 0.5051191906287936\n",
      "epoch : 491 ,weight1 : 0.7360451125096149 ,weight2 : 1.1232072079466209,bias : -0.8559593839399591, loss : 0.5049826528657863\n",
      "epoch : 492 ,weight1 : 0.7358733838445968 ,weight2 : 1.123803367724804,bias : -0.8569470469897746, loss : 0.5048464015031373\n",
      "epoch : 493 ,weight1 : 0.7357024473402197 ,weight2 : 1.1244001410792581,bias : -0.8579330395960996, loss : 0.504710434957855\n",
      "epoch : 494 ,weight1 : 0.7355323001495511 ,weight2 : 1.1249975246760133,bias : -0.8589173673779856, loss : 0.5045747516580464\n",
      "epoch : 495 ,weight1 : 0.7353629394354547 ,weight2 : 1.1255955151926809,bias : -0.8599000359349633, loss : 0.5044393500428426\n",
      "epoch : 496 ,weight1 : 0.7351943623705653 ,weight2 : 1.1261941093184253,bias : -0.8608810508470974, loss : 0.5043042285623198\n",
      "epoch : 497 ,weight1 : 0.7350265661372626 ,weight2 : 1.1267933037539384,bias : -0.8618604176750413, loss : 0.5041693856774248\n",
      "epoch : 498 ,weight1 : 0.7348595479276452 ,weight2 : 1.1273930952114113,bias : -0.8628381419600921, loss : 0.5040348198598967\n",
      "epoch : 499 ,weight1 : 0.7346933049435054 ,weight2 : 1.1279934804145084,bias : -0.8638142292242456, loss : 0.5039005295921951\n",
      "epoch : 500 ,weight1 : 0.7345278343963025 ,weight2 : 1.1285944560983399,bias : -0.8647886849702509, loss : 0.5037665133674215\n",
      "epoch : 501 ,weight1 : 0.7343631335071378 ,weight2 : 1.129196019009434,bias : -0.8657615146816654, loss : 0.5036327696892473\n",
      "epoch : 502 ,weight1 : 0.7341991995067277 ,weight2 : 1.1297981659057106,bias : -0.8667327238229099, loss : 0.5034992970718394\n",
      "epoch : 503 ,weight1 : 0.7340360296353788 ,weight2 : 1.130400893556454,bias : -0.867702317839323, loss : 0.5033660940397854\n",
      "epoch : 504 ,weight1 : 0.7338736211429613 ,weight2 : 1.1310041987422852,bias : -0.8686703021572161, loss : 0.5032331591280227\n",
      "epoch : 505 ,weight1 : 0.7337119712888833 ,weight2 : 1.1316080782551343,bias : -0.8696366821839283, loss : 0.5031004908817647\n",
      "epoch : 506 ,weight1 : 0.7335510773420649 ,weight2 : 1.1322125288982137,bias : -0.8706014633078811, loss : 0.5029680878564283\n",
      "epoch : 507 ,weight1 : 0.7333909365809123 ,weight2 : 1.1328175474859903,bias : -0.8715646508986331, loss : 0.5028359486175636\n",
      "epoch : 508 ,weight1 : 0.7332315462932913 ,weight2 : 1.1334231308441582,bias : -0.8725262503069346, loss : 0.5027040717407821\n",
      "epoch : 509 ,weight1 : 0.7330729037765026 ,weight2 : 1.134029275809611,bias : -0.8734862668647829, loss : 0.5025724558116856\n",
      "epoch : 510 ,weight1 : 0.7329150063372541 ,weight2 : 1.1346359792304144,bias : -0.8744447058854763, loss : 0.5024410994257967\n",
      "epoch : 511 ,weight1 : 0.7327578512916367 ,weight2 : 1.135243237965778,bias : -0.875401572663669, loss : 0.5023100011884886\n",
      "epoch : 512 ,weight1 : 0.732601435965097 ,weight2 : 1.1358510488860283,bias : -0.8763568724754259, loss : 0.5021791597149162\n",
      "epoch : 513 ,weight1 : 0.7324457576924118 ,weight2 : 1.1364594088725806,bias : -0.877310610578277, loss : 0.5020485736299467\n",
      "epoch : 514 ,weight1 : 0.7322908138176625 ,weight2 : 1.1370683148179115,bias : -0.8782627922112718, loss : 0.5019182415680913\n",
      "epoch : 515 ,weight1 : 0.7321366016942084 ,weight2 : 1.1376777636255309,bias : -0.8792134225950343, loss : 0.5017881621734376\n",
      "epoch : 516 ,weight1 : 0.7319831186846613 ,weight2 : 1.1382877522099544,bias : -0.8801625069318171, loss : 0.5016583340995815\n",
      "epoch : 517 ,weight1 : 0.7318303621608593 ,weight2 : 1.138898277496675,bias : -0.8811100504055559, loss : 0.501528756009561\n",
      "epoch : 518 ,weight1 : 0.7316783295038409 ,weight2 : 1.1395093364221358,bias : -0.8820560581819241, loss : 0.5013994265757882\n",
      "epoch : 519 ,weight1 : 0.731527018103819 ,weight2 : 1.140120925933702,bias : -0.8830005354083869, loss : 0.5012703444799843\n",
      "epoch : 520 ,weight1 : 0.7313764253601549 ,weight2 : 1.1407330429896323,bias : -0.8839434872142556, loss : 0.501141508413113\n",
      "epoch : 521 ,weight1 : 0.7312265486813323 ,weight2 : 1.1413456845590515,bias : -0.8848849187107426, loss : 0.5010129170753161\n",
      "epoch : 522 ,weight1 : 0.7310773854849316 ,weight2 : 1.141958847621923,bias : -0.8858248349910144, loss : 0.5008845691758473\n",
      "epoch : 523 ,weight1 : 0.7309289331976038 ,weight2 : 1.1425725291690192,bias : -0.8867632411302468, loss : 0.5007564634330082\n",
      "epoch : 524 ,weight1 : 0.7307811892550444 ,weight2 : 1.143186726201895,bias : -0.8877001421856787, loss : 0.5006285985740851\n",
      "epoch : 525 ,weight1 : 0.7306341511019679 ,weight2 : 1.1438014357328596,bias : -0.8886355431966659, loss : 0.5005009733352844\n",
      "epoch : 526 ,weight1 : 0.7304878161920815 ,weight2 : 1.1444166547849473,bias : -0.8895694491847358, loss : 0.5003735864616691\n",
      "epoch : 527 ,weight1 : 0.7303421819880592 ,weight2 : 1.14503238039189,bias : -0.8905018651536407, loss : 0.5002464367070967\n",
      "epoch : 528 ,weight1 : 0.7301972459615164 ,weight2 : 1.1456486095980896,bias : -0.8914327960894122, loss : 0.5001195228341568\n",
      "epoch : 529 ,weight1 : 0.7300530055929831 ,weight2 : 1.1462653394585893,bias : -0.8923622469604147, loss : 0.49999284361410823\n",
      "epoch : 530 ,weight1 : 0.7299094583718794 ,weight2 : 1.1468825670390455,bias : -0.8932902227173996, loss : 0.49986639782681885\n",
      "epoch : 531 ,weight1 : 0.729766601796488 ,weight2 : 1.1475002894156994,bias : -0.8942167282935587, loss : 0.49974018426070327\n",
      "epoch : 532 ,weight1 : 0.7296244333739299 ,weight2 : 1.1481185036753496,bias : -0.8951417686045783, loss : 0.49961420171266185\n",
      "epoch : 533 ,weight1 : 0.7294829506201376 ,weight2 : 1.148737206915323,bias : -0.8960653485486925, loss : 0.4994884489880219\n",
      "epoch : 534 ,weight1 : 0.7293421510598295 ,weight2 : 1.149356396243447,bias : -0.8969874730067368, loss : 0.4993629249004762\n",
      "epoch : 535 ,weight1 : 0.7292020322264843 ,weight2 : 1.1499760687780214,bias : -0.8979081468422018, loss : 0.499237628272024\n",
      "epoch : 536 ,weight1 : 0.7290625916623151 ,weight2 : 1.1505962216477896,bias : -0.8988273749012865, loss : 0.4991125579329115\n",
      "epoch : 537 ,weight1 : 0.7289238269182439 ,weight2 : 1.1512168519919115,bias : -0.899745162012952, loss : 0.4989877127215739\n",
      "epoch : 538 ,weight1 : 0.7287857355538753 ,weight2 : 1.1518379569599337,bias : -0.900661512988974, loss : 0.4988630914845762\n",
      "epoch : 539 ,weight1 : 0.7286483151374713 ,weight2 : 1.1524595337117627,bias : -0.9015764326239972, loss : 0.49873869307655583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 540 ,weight1 : 0.7285115632459255 ,weight2 : 1.1530815794176357,bias : -0.9024899256955876, loss : 0.4986145163601644\n",
      "epoch : 541 ,weight1 : 0.7283754774647372 ,weight2 : 1.1537040912580925,bias : -0.903401996964286, loss : 0.4984905602060109\n",
      "epoch : 542 ,weight1 : 0.7282400553879861 ,weight2 : 1.1543270664239476,bias : -0.9043126511736609, loss : 0.4983668234926047\n",
      "epoch : 543 ,weight1 : 0.7281052946183063 ,weight2 : 1.1549505021162618,bias : -0.9052218930503615, loss : 0.4982433051062997\n",
      "epoch : 544 ,weight1 : 0.7279711927668611 ,weight2 : 1.1555743955463136,bias : -0.9061297273041707, loss : 0.4981200039412368\n",
      "epoch : 545 ,weight1 : 0.727837747453317 ,weight2 : 1.1561987439355712,bias : -0.9070361586280579, loss : 0.4979969188992901\n",
      "epoch : 546 ,weight1 : 0.7277049563058184 ,weight2 : 1.1568235445156643,bias : -0.9079411916982314, loss : 0.4978740488900103\n",
      "epoch : 547 ,weight1 : 0.7275728169609621 ,weight2 : 1.1574487945283556,bias : -0.9088448311741918, loss : 0.49775139283056996\n",
      "epoch : 548 ,weight1 : 0.7274413270637716 ,weight2 : 1.158074491225513,bias : -0.9097470816987838, loss : 0.4976289496457092\n",
      "epoch : 549 ,weight1 : 0.7273104842676718 ,weight2 : 1.1587006318690805,bias : -0.9106479478982493, loss : 0.4975067182676809\n",
      "epoch : 550 ,weight1 : 0.7271802862344633 ,weight2 : 1.1593272137310509,bias : -0.9115474343822796, loss : 0.4973846976361984\n",
      "epoch : 551 ,weight1 : 0.7270507306342975 ,weight2 : 1.159954234093437,bias : -0.9124455457440677, loss : 0.49726288669837987\n",
      "epoch : 552 ,weight1 : 0.7269218151456505 ,weight2 : 1.1605816902482433,bias : -0.9133422865603606, loss : 0.49714128440869687\n",
      "epoch : 553 ,weight1 : 0.7267935374552982 ,weight2 : 1.1612095794974382,bias : -0.914237661391512, loss : 0.49701988972892075\n",
      "epoch : 554 ,weight1 : 0.7266658952582908 ,weight2 : 1.1618378991529255,bias : -0.9151316747815333, loss : 0.4968987016280703\n",
      "epoch : 555 ,weight1 : 0.7265388862579277 ,weight2 : 1.1624666465365159,bias : -0.9160243312581469, loss : 0.49677771908236074\n",
      "epoch : 556 ,weight1 : 0.7264125081657319 ,weight2 : 1.1630958189798994,bias : -0.9169156353328372, loss : 0.4966569410751504\n",
      "epoch : 557 ,weight1 : 0.7262867587014249 ,weight2 : 1.1637254138246167,bias : -0.9178055915009029, loss : 0.49653636659689065\n",
      "epoch : 558 ,weight1 : 0.7261616355929015 ,weight2 : 1.1643554284220312,bias : -0.9186942042415088, loss : 0.49641599464507424\n",
      "epoch : 559 ,weight1 : 0.7260371365762045 ,weight2 : 1.1649858601333007,bias : -0.9195814780177375, loss : 0.4962958242241849\n",
      "epoch : 560 ,weight1 : 0.7259132593954998 ,weight2 : 1.1656167063293494,bias : -0.9204674172766405, loss : 0.49617585434564754\n",
      "epoch : 561 ,weight1 : 0.725790001803051 ,weight2 : 1.1662479643908397,bias : -0.9213520264492905, loss : 0.4960560840277769\n",
      "epoch : 562 ,weight1 : 0.7256673615591944 ,weight2 : 1.1668796317081438,bias : -0.9222353099508321, loss : 0.4959365122957297\n",
      "epoch : 563 ,weight1 : 0.7255453364323142 ,weight2 : 1.167511705681316,bias : -0.9231172721805339, loss : 0.4958171381814547\n",
      "epoch : 564 ,weight1 : 0.725423924198817 ,weight2 : 1.1681441837200646,bias : -0.9239979175218387, loss : 0.4956979607236427\n",
      "epoch : 565 ,weight1 : 0.725303122643107 ,weight2 : 1.1687770632437233,bias : -0.9248772503424159, loss : 0.49557897896767955\n",
      "epoch : 566 ,weight1 : 0.7251829295575615 ,weight2 : 1.169410341681224,bias : -0.9257552749942115, loss : 0.495460191965597\n",
      "epoch : 567 ,weight1 : 0.7250633427425051 ,weight2 : 1.1700440164710681,bias : -0.9266319958134998, loss : 0.4953415987760253\n",
      "epoch : 568 ,weight1 : 0.7249443600061857 ,weight2 : 1.1706780850612986,bias : -0.9275074171209337, loss : 0.4952231984641448\n",
      "epoch : 569 ,weight1 : 0.7248259791647491 ,weight2 : 1.1713125449094721,bias : -0.9283815432215959, loss : 0.4951049901016399\n",
      "epoch : 570 ,weight1 : 0.7247081980422144 ,weight2 : 1.1719473934826312,bias : -0.9292543784050495, loss : 0.4949869727666502\n",
      "epoch : 571 ,weight1 : 0.7245910144704493 ,weight2 : 1.172582628257276,bias : -0.9301259269453885, loss : 0.4948691455437264\n",
      "epoch : 572 ,weight1 : 0.724474426289145 ,weight2 : 1.1732182467193366,bias : -0.9309961931012882, loss : 0.4947515075237822\n",
      "epoch : 573 ,weight1 : 0.7243584313457923 ,weight2 : 1.173854246364145,bias : -0.931865181116056, loss : 0.4946340578040482\n",
      "epoch : 574 ,weight1 : 0.7242430274956557 ,weight2 : 1.1744906246964073,bias : -0.9327328952176811, loss : 0.49451679548802774\n",
      "epoch : 575 ,weight1 : 0.7241282126017501 ,weight2 : 1.1751273792301757,bias : -0.9335993396188853, loss : 0.4943997196854504\n",
      "epoch : 576 ,weight1 : 0.7240139845348154 ,weight2 : 1.1757645074888208,bias : -0.9344645185171727, loss : 0.4942828295122267\n",
      "epoch : 577 ,weight1 : 0.7239003411732922 ,weight2 : 1.1764020070050036,bias : -0.9353284360948799, loss : 0.4941661240904044\n",
      "epoch : 578 ,weight1 : 0.7237872804032974 ,weight2 : 1.1770398753206484,bias : -0.9361910965192259, loss : 0.4940496025481238\n",
      "epoch : 579 ,weight1 : 0.7236748001185996 ,weight2 : 1.177678109986914,bias : -0.937052503942362, loss : 0.49393326401957277\n",
      "epoch : 580 ,weight1 : 0.7235628982205948 ,weight2 : 1.178316708564167,bias : -0.9379126625014209, loss : 0.4938171076449444\n",
      "epoch : 581 ,weight1 : 0.7234515726182819 ,weight2 : 1.1789556686219531,bias : -0.9387715763185672, loss : 0.4937011325703921\n",
      "epoch : 582 ,weight1 : 0.7233408212282383 ,weight2 : 1.1795949877389704,bias : -0.9396292495010464, loss : 0.4935853379479873\n",
      "epoch : 583 ,weight1 : 0.723230641974596 ,weight2 : 1.1802346635030412,bias : -0.9404856861412343, loss : 0.49346972293567665\n",
      "epoch : 584 ,weight1 : 0.723121032789017 ,weight2 : 1.1808746935110845,bias : -0.9413408903166863, loss : 0.49335428669723813\n",
      "epoch : 585 ,weight1 : 0.7230119916106692 ,weight2 : 1.1815150753690886,bias : -0.9421948660901869, loss : 0.4932390284022409\n",
      "epoch : 586 ,weight1 : 0.7229035163862023 ,weight2 : 1.1821558066920832,bias : -0.9430476175097984, loss : 0.4931239472260014\n",
      "epoch : 587 ,weight1 : 0.7227956050697236 ,weight2 : 1.1827968851041124,bias : -0.94389914860891, loss : 0.4930090423495425\n",
      "epoch : 588 ,weight1 : 0.722688255622774 ,weight2 : 1.1834383082382067,bias : -0.9447494634062868, loss : 0.4928943129595524\n",
      "epoch : 589 ,weight1 : 0.7225814660143036 ,weight2 : 1.184080073736356,bias : -0.9455985659061186, loss : 0.492779758248342\n",
      "epoch : 590 ,weight1 : 0.7224752342206485 ,weight2 : 1.184722179249482,bias : -0.9464464600980682, loss : 0.4926653774138066\n",
      "epoch : 591 ,weight1 : 0.7223695582255062 ,weight2 : 1.1853646224374108,bias : -0.9472931499573206, loss : 0.49255116965938234\n",
      "epoch : 592 ,weight1 : 0.7222644360199119 ,weight2 : 1.1860074009688455,bias : -0.9481386394446308, loss : 0.49243713419400875\n",
      "epoch : 593 ,weight1 : 0.7221598656022146 ,weight2 : 1.1866505125213391,bias : -0.9489829325063726, loss : 0.49232327023208694\n",
      "epoch : 594 ,weight1 : 0.7220558449780535 ,weight2 : 1.1872939547812673,bias : -0.9498260330745865, loss : 0.49220957699344026\n",
      "epoch : 595 ,weight1 : 0.7219523721603341 ,weight2 : 1.1879377254438008,bias : -0.9506679450670281, loss : 0.49209605370327564\n",
      "epoch : 596 ,weight1 : 0.7218494451692045 ,weight2 : 1.1885818222128788,bias : -0.9515086723872164, loss : 0.4919826995921432\n",
      "epoch : 597 ,weight1 : 0.7217470620320313 ,weight2 : 1.1892262428011808,bias : -0.9523482189244807, loss : 0.4918695138958985\n",
      "epoch : 598 ,weight1 : 0.721645220783377 ,weight2 : 1.189870984930101,bias : -0.9531865885540097, loss : 0.4917564958556632\n",
      "epoch : 599 ,weight1 : 0.7215439194649756 ,weight2 : 1.1905160463297197,bias : -0.9540237851368982, loss : 0.49164364471778754\n",
      "epoch : 600 ,weight1 : 0.7214431561257093 ,weight2 : 1.1911614247387774,bias : -0.9548598125201954, loss : 0.4915309597338114\n",
      "epoch : 601 ,weight1 : 0.7213429288215849 ,weight2 : 1.191807117904647,bias : -0.9556946745369516, loss : 0.49141844016042646\n",
      "epoch : 602 ,weight1 : 0.7212432356157107 ,weight2 : 1.1924531235833074,bias : -0.9565283750062663, loss : 0.49130608525943964\n",
      "epoch : 603 ,weight1 : 0.7211440745782728 ,weight2 : 1.1930994395393162,bias : -0.9573609177333352, loss : 0.49119389429773525\n",
      "epoch : 604 ,weight1 : 0.7210454437865119 ,weight2 : 1.1937460635457833,bias : -0.9581923065094973, loss : 0.4910818665472382\n",
      "epoch : 605 ,weight1 : 0.7209473413247002 ,weight2 : 1.1943929933843433,bias : -0.9590225451122819, loss : 0.49097000128487606\n",
      "epoch : 606 ,weight1 : 0.7208497652841176 ,weight2 : 1.1950402268451294,bias : -0.9598516373054558, loss : 0.49085829779254514\n",
      "epoch : 607 ,weight1 : 0.7207527137630292 ,weight2 : 1.1956877617267465,bias : -0.9606795868390695, loss : 0.49074675535707174\n",
      "epoch : 608 ,weight1 : 0.7206561848666617 ,weight2 : 1.1963355958362443,bias : -0.9615063974495047, loss : 0.49063537327017726\n",
      "epoch : 609 ,weight1 : 0.7205601767071804 ,weight2 : 1.1969837269890904,bias : -0.9623320728595205, loss : 0.4905241508284429\n",
      "epoch : 610 ,weight1 : 0.7204646874036664 ,weight2 : 1.1976321530091447,bias : -0.9631566167782996, loss : 0.49041308733327327\n",
      "epoch : 611 ,weight1 : 0.7203697150820932 ,weight2 : 1.1982808717286315,bias : -0.9639800329014951, loss : 0.49030218209086235\n",
      "epoch : 612 ,weight1 : 0.7202752578753042 ,weight2 : 1.1989298809881137,bias : -0.9648023249112767, loss : 0.4901914344121568\n",
      "epoch : 613 ,weight1 : 0.7201813139229893 ,weight2 : 1.1995791786364665,bias : -0.9656234964763766, loss : 0.49008084361282334\n",
      "epoch : 614 ,weight1 : 0.7200878813716627 ,weight2 : 1.2002287625308503,bias : -0.9664435512521357, loss : 0.48997040901321254\n",
      "epoch : 615 ,weight1 : 0.7199949583746394 ,weight2 : 1.200878630536685,bias : -0.9672624928805496, loss : 0.4898601299383258\n",
      "epoch : 616 ,weight1 : 0.7199025430920133 ,weight2 : 1.201528780527623,bias : -0.9680803249903139, loss : 0.4897500057177808\n",
      "epoch : 617 ,weight1 : 0.7198106336906335 ,weight2 : 1.202179210385523,bias : -0.9688970511968708, loss : 0.4896400356857777\n",
      "epoch : 618 ,weight1 : 0.7197192283440825 ,weight2 : 1.2028299180004243,bias : -0.9697126751024536, loss : 0.4895302191810656\n",
      "epoch : 619 ,weight1 : 0.7196283252326533 ,weight2 : 1.20348090127052,bias : -0.970527200296133, loss : 0.48942055554691033\n",
      "epoch : 620 ,weight1 : 0.7195379225433268 ,weight2 : 1.2041321581021314,bias : -0.9713406303538621, loss : 0.48931104413106\n",
      "epoch : 621 ,weight1 : 0.7194480184697495 ,weight2 : 1.2047836864096808,bias : -0.9721529688385214, loss : 0.4892016842857129\n",
      "epoch : 622 ,weight1 : 0.7193586112122108 ,weight2 : 1.2054354841156667,bias : -0.9729642192999644, loss : 0.48909247536748507\n",
      "epoch : 623 ,weight1 : 0.7192696989776209 ,weight2 : 1.2060875491506369,bias : -0.9737743852750621, loss : 0.48898341673737816\n",
      "epoch : 624 ,weight1 : 0.7191812799794884 ,weight2 : 1.206739879453163,bias : -0.9745834702877484, loss : 0.488874507760746\n",
      "epoch : 625 ,weight1 : 0.719093352437898 ,weight2 : 1.207392472969814,bias : -0.9753914778490644, loss : 0.488765747807265\n",
      "epoch : 626 ,weight1 : 0.7190059145794879 ,weight2 : 1.2080453276551308,bias : -0.9761984114572033, loss : 0.4886571362509003\n",
      "epoch : 627 ,weight1 : 0.7189189646374284 ,weight2 : 1.2086984414716007,bias : -0.9770042745975547, loss : 0.4885486724698759\n",
      "epoch : 628 ,weight1 : 0.7188325008513993 ,weight2 : 1.2093518123896303,bias : -0.9778090707427494, loss : 0.488440355846643\n",
      "epoch : 629 ,weight1 : 0.7187465214675676 ,weight2 : 1.2100054383875214,bias : -0.9786128033527032, loss : 0.48833218576784865\n",
      "epoch : 630 ,weight1 : 0.7186610247385662 ,weight2 : 1.2106593174514444,bias : -0.9794154758746616, loss : 0.48822416162430576\n",
      "epoch : 631 ,weight1 : 0.7185760089234712 ,weight2 : 1.2113134475754126,bias : -0.9802170917432435, loss : 0.4881162828109619\n",
      "epoch : 632 ,weight1 : 0.7184914722877805 ,weight2 : 1.2119678267612568,bias : -0.9810176543804852, loss : 0.48800854872686944\n",
      "epoch : 633 ,weight1 : 0.7184074131033917 ,weight2 : 1.2126224530186,bias : -0.9818171671958843, loss : 0.4879009587751555\n",
      "epoch : 634 ,weight1 : 0.7183238296485804 ,weight2 : 1.2132773243648318,bias : -0.9826156335864437, loss : 0.48779351236299184\n",
      "epoch : 635 ,weight1 : 0.7182407202079784 ,weight2 : 1.2139324388250825,bias : -0.9834130569367143, loss : 0.48768620890156517\n",
      "epoch : 636 ,weight1 : 0.7181580830725518 ,weight2 : 1.2145877944321986,bias : -0.9842094406188397, loss : 0.4875790478060481\n",
      "epoch : 637 ,weight1 : 0.71807591653958 ,weight2 : 1.2152433892267163,bias : -0.9850047879925987, loss : 0.48747202849556986\n",
      "epoch : 638 ,weight1 : 0.7179942189126334 ,weight2 : 1.2158992212568374,bias : -0.9857991024054487, loss : 0.4873651503931866\n",
      "epoch : 639 ,weight1 : 0.7179129885015522 ,weight2 : 1.2165552885784034,bias : -0.9865923871925689, loss : 0.48725841292585415\n",
      "epoch : 640 ,weight1 : 0.7178322236224248 ,weight2 : 1.2172115892548707,bias : -0.9873846456769035, loss : 0.48715181552439707\n",
      "epoch : 641 ,weight1 : 0.7177519225975667 ,weight2 : 1.217868121357285,bias : -0.9881758811692045, loss : 0.48704535762348256\n",
      "epoch : 642 ,weight1 : 0.7176720837554986 ,weight2 : 1.2185248829642568,bias : -0.9889660969680741, loss : 0.48693903866159144\n",
      "epoch : 643 ,weight1 : 0.7175927054309256 ,weight2 : 1.2191818721619354,bias : -0.9897552963600079, loss : 0.4868328580809891\n",
      "epoch : 644 ,weight1 : 0.7175137859647153 ,weight2 : 1.2198390870439855,bias : -0.990543482619437, loss : 0.4867268153276996\n",
      "epoch : 645 ,weight1 : 0.7174353237038774 ,weight2 : 1.2204965257115608,bias : -0.9913306590087709, loss : 0.48662090985147705\n",
      "epoch : 646 ,weight1 : 0.717357317001542 ,weight2 : 1.22115418627328,bias : -0.9921168287784393, loss : 0.4865151411057782\n",
      "epoch : 647 ,weight1 : 0.7172797642169386 ,weight2 : 1.2218120668452017,bias : -0.9929019951669346, loss : 0.4864095085477352\n",
      "epoch : 648 ,weight1 : 0.717202663715375 ,weight2 : 1.2224701655507997,bias : -0.9936861614008539, loss : 0.48630401163812925\n",
      "epoch : 649 ,weight1 : 0.7171260138682165 ,weight2 : 1.2231284805209384,bias : -0.9944693306949409, loss : 0.4861986498413633\n",
      "epoch : 650 ,weight1 : 0.7170498130528647 ,weight2 : 1.2237870098938481,bias : -0.995251506252128, loss : 0.48609342262543587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 651 ,weight1 : 0.716974059652737 ,weight2 : 1.2244457518151004,bias : -0.9960326912635775, loss : 0.4859883294619137\n",
      "epoch : 652 ,weight1 : 0.7168987520572453 ,weight2 : 1.2251047044375833,bias : -0.9968128889087238, loss : 0.4858833698259065\n",
      "epoch : 653 ,weight1 : 0.7168238886617755 ,weight2 : 1.2257638659214776,bias : -0.9975921023553143, loss : 0.4857785431960409\n",
      "epoch : 654 ,weight1 : 0.7167494678676669 ,weight2 : 1.2264232344342314,bias : -0.9983703347594511, loss : 0.48567384905443434\n",
      "epoch : 655 ,weight1 : 0.7166754880821912 ,weight2 : 1.227082808150537,bias : -0.9991475892656324, loss : 0.48556928688666884\n",
      "epoch : 656 ,weight1 : 0.7166019477185321 ,weight2 : 1.2277425852523054,bias : -0.9999238690067932, loss : 0.48546485618176666\n",
      "epoch : 657 ,weight1 : 0.7165288451957648 ,weight2 : 1.2284025639286427,bias : -1.0006991771043467, loss : 0.4853605564321647\n",
      "epoch : 658 ,weight1 : 0.7164561789388352 ,weight2 : 1.2290627423758256,bias : -1.001473516668225, loss : 0.4852563871336881\n",
      "epoch : 659 ,weight1 : 0.7163839473785399 ,weight2 : 1.2297231187972775,bias : -1.0022468907969198, loss : 0.48515234778552807\n",
      "epoch : 660 ,weight1 : 0.7163121489515055 ,weight2 : 1.2303836914035444,bias : -1.0030193025775231, loss : 0.4850484378902144\n",
      "epoch : 661 ,weight1 : 0.7162407821001683 ,weight2 : 1.2310444584122708,bias : -1.0037907550857683, loss : 0.4849446569535923\n",
      "epoch : 662 ,weight1 : 0.716169845272754 ,weight2 : 1.2317054180481755,bias : -1.0045612513860696, loss : 0.4848410044847981\n",
      "epoch : 663 ,weight1 : 0.7160993369232576 ,weight2 : 1.2323665685430278,bias : -1.0053307945315628, loss : 0.4847374799962342\n",
      "epoch : 664 ,weight1 : 0.716029255511423 ,weight2 : 1.2330279081356241,bias : -1.006099387564146, loss : 0.484634083003546\n",
      "epoch : 665 ,weight1 : 0.7159595995027235 ,weight2 : 1.2336894350717638,bias : -1.0068670335145187, loss : 0.48453081302559786\n",
      "epoch : 666 ,weight1 : 0.7158903673683407 ,weight2 : 1.2343511476042248,bias : -1.0076337354022227, loss : 0.48442766958444883\n",
      "epoch : 667 ,weight1 : 0.7158215575851454 ,weight2 : 1.235013043992741,bias : -1.0083994962356813, loss : 0.4843246522053294\n",
      "epoch : 668 ,weight1 : 0.7157531686356774 ,weight2 : 1.235675122503978,bias : -1.009164319012239, loss : 0.4842217604166189\n",
      "epoch : 669 ,weight1 : 0.7156851990081252 ,weight2 : 1.2363373814115097,bias : -1.0099282067182018, loss : 0.4841189937498215\n",
      "epoch : 670 ,weight1 : 0.7156176471963069 ,weight2 : 1.236999818995795,bias : -1.0106911623288757, loss : 0.48401635173954327\n",
      "epoch : 671 ,weight1 : 0.7155505116996498 ,weight2 : 1.2376624335441535,bias : -1.0114531888086067, loss : 0.48391383392347026\n",
      "epoch : 672 ,weight1 : 0.7154837910231707 ,weight2 : 1.2383252233507431,bias : -1.0122142891108201, loss : 0.48381143984234437\n",
      "epoch : 673 ,weight1 : 0.7154174836774567 ,weight2 : 1.2389881867165362,bias : -1.0129744661780593, loss : 0.4837091690399424\n",
      "epoch : 674 ,weight1 : 0.7153515881786452 ,weight2 : 1.2396513219492964,bias : -1.013733722942025, loss : 0.48360702106305253\n",
      "epoch : 675 ,weight1 : 0.7152861030484043 ,weight2 : 1.2403146273635552,bias : -1.0144920623236138, loss : 0.48350499546145287\n",
      "epoch : 676 ,weight1 : 0.7152210268139138 ,weight2 : 1.240978101280589,bias : -1.0152494872329578, loss : 0.48340309178788926\n",
      "epoch : 677 ,weight1 : 0.7151563580078447 ,weight2 : 1.2416417420283958,bias : -1.0160060005694624, loss : 0.4833013095980533\n",
      "epoch : 678 ,weight1 : 0.715092095168341 ,weight2 : 1.2423055479416725,bias : -1.016761605221845, loss : 0.48319964845056085\n",
      "epoch : 679 ,weight1 : 0.7150282368389997 ,weight2 : 1.2429695173617914,bias : -1.017516304068174, loss : 0.4830981079069306\n",
      "epoch : 680 ,weight1 : 0.7149647815688515 ,weight2 : 1.2436336486367776,bias : -1.0182700999759065, loss : 0.48299668753156233\n",
      "epoch : 681 ,weight1 : 0.7149017279123417 ,weight2 : 1.2442979401212861,bias : -1.0190229958019266, loss : 0.48289538689171607\n",
      "epoch : 682 ,weight1 : 0.7148390744293113 ,weight2 : 1.2449623901765787,bias : -1.0197749943925838, loss : 0.4827942055574905\n",
      "epoch : 683 ,weight1 : 0.7147768196849772 ,weight2 : 1.2456269971705014,bias : -1.0205260985837308, loss : 0.48269314310180356\n",
      "epoch : 684 ,weight1 : 0.7147149622499138 ,weight2 : 1.246291759477462,bias : -1.0212763112007612, loss : 0.48259219910036955\n",
      "epoch : 685 ,weight1 : 0.7146535007000336 ,weight2 : 1.246956675478407,bias : -1.0220256350586476, loss : 0.4824913731316802\n",
      "epoch : 686 ,weight1 : 0.7145924336165684 ,weight2 : 1.2476217435607986,bias : -1.0227740729619788, loss : 0.4823906647769832\n",
      "epoch : 687 ,weight1 : 0.7145317595860504 ,weight2 : 1.2482869621185935,bias : -1.0235216277049974, loss : 0.482290073620263\n",
      "epoch : 688 ,weight1 : 0.7144714772002932 ,weight2 : 1.2489523295522194,bias : -1.0242683020716377, loss : 0.48218959924821936\n",
      "epoch : 689 ,weight1 : 0.7144115850563733 ,weight2 : 1.2496178442685526,bias : -1.0250140988355623, loss : 0.48208924125024877\n",
      "epoch : 690 ,weight1 : 0.7143520817566108 ,weight2 : 1.2502835046808962,bias : -1.0257590207601994, loss : 0.48198899921842303\n",
      "epoch : 691 ,weight1 : 0.7142929659085515 ,weight2 : 1.2509493092089572,bias : -1.0265030705987803, loss : 0.48188887274747083\n",
      "epoch : 692 ,weight1 : 0.7142342361249477 ,weight2 : 1.2516152562788243,bias : -1.0272462510943758, loss : 0.481788861434758\n",
      "epoch : 693 ,weight1 : 0.7141758910237398 ,weight2 : 1.2522813443229464,bias : -1.0279885649799334, loss : 0.48168896488026747\n",
      "epoch : 694 ,weight1 : 0.7141179292280377 ,weight2 : 1.2529475717801097,bias : -1.0287300149783138, loss : 0.48158918268658085\n",
      "epoch : 695 ,weight1 : 0.7140603493661026 ,weight2 : 1.253613937095416,bias : -1.0294706038023274, loss : 0.481489514458858\n",
      "epoch : 696 ,weight1 : 0.7140031500713282 ,weight2 : 1.2542804387202604,bias : -1.030210334154771, loss : 0.48138995980481997\n",
      "epoch : 697 ,weight1 : 0.7139463299822226 ,weight2 : 1.25494707511231,bias : -1.0309492087284642, loss : 0.481290518334728\n",
      "epoch : 698 ,weight1 : 0.7138898877423902 ,weight2 : 1.255613844735481,bias : -1.0316872302062852, loss : 0.4811911896613669\n",
      "epoch : 699 ,weight1 : 0.7138338220005127 ,weight2 : 1.256280746059918,bias : -1.0324244012612074, loss : 0.48109197340002474\n",
      "epoch : 700 ,weight1 : 0.7137781314103319 ,weight2 : 1.256947777561971,bias : -1.0331607245563355, loss : 0.48099286916847556\n",
      "epoch : 701 ,weight1 : 0.7137228146306307 ,weight2 : 1.2576149377241754,bias : -1.0338962027449408, loss : 0.4808938765869603\n",
      "epoch : 702 ,weight1 : 0.7136678703252157 ,weight2 : 1.2582822250352281,bias : -1.0346308384704974, loss : 0.48079499527816927\n",
      "epoch : 703 ,weight1 : 0.7136132971628988 ,weight2 : 1.2589496379899678,bias : -1.0353646343667182, loss : 0.48069622486722385\n",
      "epoch : 704 ,weight1 : 0.7135590938174791 ,weight2 : 1.2596171750893523,bias : -1.03609759305759, loss : 0.48059756498165845\n",
      "epoch : 705 ,weight1 : 0.7135052589677253 ,weight2 : 1.260284834840438,bias : -1.0368297171574086, loss : 0.48049901525140326\n",
      "epoch : 706 ,weight1 : 0.7134517912973578 ,weight2 : 1.2609526157563575,bias : -1.0375610092708152, loss : 0.4804005753087654\n",
      "epoch : 707 ,weight1 : 0.7133986894950307 ,weight2 : 1.2616205163562988,bias : -1.0382914719928307, loss : 0.4803022447884134\n",
      "epoch : 708 ,weight1 : 0.7133459522543142 ,weight2 : 1.2622885351654838,bias : -1.0390211079088911, loss : 0.4802040233273578\n",
      "epoch : 709 ,weight1 : 0.7132935782736768 ,weight2 : 1.2629566707151474,bias : -1.039749919594883, loss : 0.48010591056493546\n",
      "epoch : 710 ,weight1 : 0.7132415662564677 ,weight2 : 1.263624921542516,bias : -1.0404779096171775, loss : 0.48000790614279093\n",
      "epoch : 711 ,weight1 : 0.7131899149108992 ,weight2 : 1.2642932861907858,bias : -1.0412050805326658, loss : 0.47991000970486153\n",
      "epoch : 712 ,weight1 : 0.7131386229500293 ,weight2 : 1.2649617632091035,bias : -1.0419314348887936, loss : 0.47981222089735814\n",
      "epoch : 713 ,weight1 : 0.7130876890917437 ,weight2 : 1.2656303511525429,bias : -1.0426569752235957, loss : 0.4797145393687501\n",
      "epoch : 714 ,weight1 : 0.7130371120587392 ,weight2 : 1.266299048582086,bias : -1.0433817040657303, loss : 0.47961696476974824\n",
      "epoch : 715 ,weight1 : 0.7129868905785056 ,weight2 : 1.266967854064601,bias : -1.0441056239345134, loss : 0.47951949675328764\n",
      "epoch : 716 ,weight1 : 0.7129370233833087 ,weight2 : 1.2676367661728218,bias : -1.0448287373399532, loss : 0.4794221349745126\n",
      "epoch : 717 ,weight1 : 0.712887509210173 ,weight2 : 1.2683057834853273,bias : -1.045551046782784, loss : 0.47932487909075905\n",
      "epoch : 718 ,weight1 : 0.7128383468008643 ,weight2 : 1.2689749045865204,bias : -1.0462725547545002, loss : 0.47922772876153913\n",
      "epoch : 719 ,weight1 : 0.712789534901873 ,weight2 : 1.2696441280666075,bias : -1.0469932637373902, loss : 0.4791306836485256\n",
      "epoch : 720 ,weight1 : 0.7127410722643963 ,weight2 : 1.270313452521578,bias : -1.0477131762045706, loss : 0.4790337434155344\n",
      "epoch : 721 ,weight1 : 0.7126929576443218 ,weight2 : 1.2709828765531836,bias : -1.0484322946200195, loss : 0.4789369077285108\n",
      "epoch : 722 ,weight1 : 0.7126451898022101 ,weight2 : 1.2716523987689181,bias : -1.0491506214386097, loss : 0.478840176255512\n",
      "epoch : 723 ,weight1 : 0.712597767503278 ,weight2 : 1.2723220177819965,bias : -1.049868159106143, loss : 0.4787435486666933\n",
      "epoch : 724 ,weight1 : 0.7125506895173813 ,weight2 : 1.272991732211335,bias : -1.0505849100593825, loss : 0.47864702463429115\n",
      "epoch : 725 ,weight1 : 0.7125039546189987 ,weight2 : 1.273661540681531,bias : -1.051300876726087, loss : 0.47855060383260867\n",
      "epoch : 726 ,weight1 : 0.7124575615872143 ,weight2 : 1.2743314418228417,bias : -1.0520160615250433, loss : 0.4784542859380002\n",
      "epoch : 727 ,weight1 : 0.7124115092057008 ,weight2 : 1.275001434271165,bias : -1.0527304668660997, loss : 0.4783580706288561\n",
      "epoch : 728 ,weight1 : 0.7123657962627036 ,weight2 : 1.2756715166680195,bias : -1.0534440951501984, loss : 0.4782619575855886\n",
      "epoch : 729 ,weight1 : 0.7123204215510233 ,weight2 : 1.2763416876605231,bias : -1.0541569487694087, loss : 0.47816594649061567\n",
      "epoch : 730 ,weight1 : 0.7122753838679996 ,weight2 : 1.2770119459013745,bias : -1.0548690301069594, loss : 0.4780700370283465\n",
      "epoch : 731 ,weight1 : 0.7122306820154947 ,weight2 : 1.2776822900488323,bias : -1.055580341537272, loss : 0.4779742288851683\n",
      "epoch : 732 ,weight1 : 0.7121863147998766 ,weight2 : 1.2783527187666957,bias : -1.0562908854259923, loss : 0.4778785217494299\n",
      "epoch : 733 ,weight1 : 0.712142281032003 ,weight2 : 1.279023230724284,bias : -1.0570006641300234, loss : 0.4777829153114285\n",
      "epoch : 734 ,weight1 : 0.712098579527205 ,weight2 : 1.2796938245964173,bias : -1.0577096799975578, loss : 0.47768740926339465\n",
      "epoch : 735 ,weight1 : 0.71205520910527 ,weight2 : 1.2803644990633969,bias : -1.0584179353681096, loss : 0.4775920032994786\n",
      "epoch : 736 ,weight1 : 0.7120121685904264 ,weight2 : 1.2810352528109852,bias : -1.059125432572546, loss : 0.47749669711573595\n",
      "epoch : 737 ,weight1 : 0.711969456811327 ,weight2 : 1.2817060845303863,bias : -1.0598321739331205, loss : 0.4774014904101133\n",
      "epoch : 738 ,weight1 : 0.7119270726010325 ,weight2 : 1.2823769929182263,bias : -1.0605381617635032, loss : 0.4773063828824352\n",
      "epoch : 739 ,weight1 : 0.711885014796996 ,weight2 : 1.2830479766765341,bias : -1.061243398368814, loss : 0.4772113742343896\n",
      "epoch : 740 ,weight1 : 0.7118432822410464 ,weight2 : 1.283719034512722,bias : -1.061947886045653, loss : 0.47711646416951436\n",
      "epoch : 741 ,weight1 : 0.711801873779373 ,weight2 : 1.284390165139566,bias : -1.062651627082133, loss : 0.477021652393184\n",
      "epoch : 742 ,weight1 : 0.7117607882625087 ,weight2 : 1.2850613672751863,bias : -1.0633546237579095, loss : 0.4769269386125952\n",
      "epoch : 743 ,weight1 : 0.7117200245453148 ,weight2 : 1.2857326396430289,bias : -1.0640568783442141, loss : 0.4768323225367548\n",
      "epoch : 744 ,weight1 : 0.7116795814869651 ,weight2 : 1.2864039809718457,bias : -1.064758393103884, loss : 0.47673780387646586\n",
      "epoch : 745 ,weight1 : 0.7116394579509295 ,weight2 : 1.2870753899956755,bias : -1.0654591702913938, loss : 0.47664338234431447\n",
      "epoch : 746 ,weight1 : 0.7115996528049591 ,weight2 : 1.2877468654538249,bias : -1.0661592121528862, loss : 0.4765490576546557\n",
      "epoch : 747 ,weight1 : 0.7115601649210697 ,weight2 : 1.2884184060908495,bias : -1.0668585209262031, loss : 0.47645482952360274\n",
      "epoch : 748 ,weight1 : 0.7115209931755266 ,weight2 : 1.2890900106565344,bias : -1.0675570988409164, loss : 0.4763606976690122\n",
      "epoch : 749 ,weight1 : 0.7114821364488291 ,weight2 : 1.289761677905876,bias : -1.0682549481183587, loss : 0.4762666618104719\n",
      "epoch : 750 ,weight1 : 0.7114435936256944 ,weight2 : 1.2904334065990626,bias : -1.0689520709716536, loss : 0.47617272166928837\n",
      "epoch : 751 ,weight1 : 0.7114053635950429 ,weight2 : 1.2911051955014559,bias : -1.0696484696057464, loss : 0.476078876968474\n",
      "epoch : 752 ,weight1 : 0.7113674452499821 ,weight2 : 1.2917770433835718,bias : -1.0703441462174346, loss : 0.47598512743273486\n",
      "epoch : 753 ,weight1 : 0.7113298374877913 ,weight2 : 1.2924489490210627,bias : -1.0710391029953976, loss : 0.47589147278845706\n",
      "epoch : 754 ,weight1 : 0.7112925392099066 ,weight2 : 1.2931209111946975,bias : -1.071733342120228, loss : 0.4757979127636962\n",
      "epoch : 755 ,weight1 : 0.7112555493219053 ,weight2 : 1.2937929286903442,bias : -1.0724268657644602, loss : 0.4757044470881641\n",
      "epoch : 756 ,weight1 : 0.7112188667334906 ,weight2 : 1.294465000298951,bias : -1.0731196760926016, loss : 0.47561107549321646\n",
      "epoch : 757 ,weight1 : 0.7111824903584767 ,weight2 : 1.2951371248165275,bias : -1.0738117752611616, loss : 0.4755177977118415\n",
      "epoch : 758 ,weight1 : 0.7111464191147735 ,weight2 : 1.295809301044127,bias : -1.0745031654186818, loss : 0.4754246134786478\n",
      "epoch : 759 ,weight1 : 0.7111106519243715 ,weight2 : 1.296481527787827,bias : -1.075193848705766, loss : 0.4753315225298519\n",
      "epoch : 760 ,weight1 : 0.7110751877133267 ,weight2 : 1.2971538038587125,bias : -1.0758838272551088, loss : 0.4752385246032669\n",
      "epoch : 761 ,weight1 : 0.7110400254117456 ,weight2 : 1.2978261280728565,bias : -1.0765731031915258, loss : 0.4751456194382908\n",
      "epoch : 762 ,weight1 : 0.7110051639537706 ,weight2 : 1.2984984992513022,bias : -1.0772616786319826, loss : 0.47505280677589523\n",
      "epoch : 763 ,weight1 : 0.7109706022775644 ,weight2 : 1.299170916220045,bias : -1.0779495556856247, loss : 0.4749600863586129\n",
      "epoch : 764 ,weight1 : 0.7109363393252959 ,weight2 : 1.2998433778100147,bias : -1.0786367364538054, loss : 0.4748674579305272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7109363393252959,\n",
       " 1.2998433778100147,\n",
       " -1.0786367364538054,\n",
       " 0.4748674579305272)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scale['Age'],X_train_scale['Affordability'],y_train,1000,0.4749)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last loss is same as in model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
