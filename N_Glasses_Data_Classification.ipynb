{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glasses,No-Glasses Images Classification using Neural Net and OpenCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import PIL\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('DataSets/Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_path = data_path.glob('glasses/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_glasses_path = data_path.glob('no_glasses/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_data = list(data_path.glob('glasses/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_glasses_data = list(data_path.glob('no_glasses/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imread(str(glasses_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_data = {\n",
    "    \n",
    "    'glasses': glasses_data,\n",
    "    'no_glasses': no_glasses_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_labels = {\n",
    "    \n",
    "    'glasses': 0,\n",
    "    'no_glasses': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = [],[]\n",
    "\n",
    "for class_name , images in classes_data.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resize_image = cv2.resize(img,(180,180))\n",
    "        X.append(resize_image)\n",
    "        y.append(classes_labels[class_name])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scale,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    \n",
    "#     cnn\n",
    "    keras.layers.Conv2D(40,3,padding = 'same',activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Conv2D(80,3,padding = 'same',activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Conv2D(100,3,padding = 'same',activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    \n",
    "#     dense\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10,activation = 'relu'),\n",
    "    keras.layers.Dense(2,activation = 'softmax')\n",
    "\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "123/123 [==============================] - 95s 746ms/step - loss: 0.2705 - accuracy: 0.8483\n",
      "Epoch 2/5\n",
      "123/123 [==============================] - 91s 738ms/step - loss: 0.0401 - accuracy: 0.9876\n",
      "Epoch 3/5\n",
      "123/123 [==============================] - 88s 712ms/step - loss: 0.0204 - accuracy: 0.9942\n",
      "Epoch 4/5\n",
      "123/123 [==============================] - 94s 766ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 5/5\n",
      "123/123 [==============================] - 91s 742ms/step - loss: 0.0044 - accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2a28f8a00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0054 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005382537376135588, 0.9989837408065796]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for i in range(len(y_p)):\n",
    "    predicted.append(np.argmax(y_p[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = y_test\n",
    "truth[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       555\n",
      "           1       1.00      1.00      1.00       429\n",
      "\n",
      "    accuracy                           1.00       984\n",
      "   macro avg       1.00      1.00      1.00       984\n",
      "weighted avg       1.00      1.00      1.00       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(truth,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(truth,predicted)\n",
    "import seaborn as sn\n",
    "sn.heatmap(cm , annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_path = 'DataSets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('DataSets')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = pathlib.Path(my_data_path)\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_data = list(my_data.glob('My_Glasses_Data/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('DataSets/My_Glasses_Data/glasses.1.jpg'),\n",
       " WindowsPath('DataSets/My_Glasses_Data/glasses.2.jpg'),\n",
       " WindowsPath('DataSets/My_Glasses_Data/glasses.3.jpg'),\n",
       " WindowsPath('DataSets/My_Glasses_Data/glasses.4.jpg'),\n",
       " WindowsPath('DataSets/My_Glasses_Data/glasses.5.jpg'),\n",
       " WindowsPath('DataSets/My_Glasses_Data/glasses.6.jpg'),\n",
       " WindowsPath('DataSets/My_Glasses_Data/glasses.7.jpg')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glasses_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_imgs = []\n",
    "for i in range(len(glasses_data)):\n",
    "    img = cv2.imread(str(glasses_data[i]))\n",
    "    resize = cv2.resize(img,(180,180))\n",
    "    resize_imgs.append(resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_imgs = np.array(resize_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_glasses_data = resize_imgs / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 180, 180, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_glasses_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_p = model.predict(my_glasses_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prediction = []\n",
    "for i in range(len(my_p)):\n",
    "    my_prediction.append(np.argmax(my_p[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(resize_imgs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
