{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Methods and Checking Accuracy and F1-score using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd .read_csv(\"DataSets/Customer_Churn_Cleaned.csv\")\n",
    "df.drop(columns = ['Unnamed: 0'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Churn'])\n",
    "y = df.Churn\n",
    "class_0 = df[df['Churn'] == 0]\n",
    "class_1 = df[df['Churn'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownSampling(y0,y1,df):\n",
    "        \n",
    "        class_0_count,class_1_count = df.Churn.value_counts()\n",
    "        low_count = min(class_0_count,class_1_count)\n",
    "        \n",
    "        if low_count == class_0_count:\n",
    "            y1_DS = y1.sample(low_count)\n",
    "#             Here we down sample y1\n",
    "            df_set1 = pd.concat([y1_DS,y0])\n",
    "    \n",
    "        if low_count == class_1_count:\n",
    "            y0_DS = y0.sample(low_count)\n",
    "#             Here we down sample y1\n",
    "            df_set1 = pd.concat([y0_DS,y1])\n",
    "    \n",
    "        X = df_set1.drop(columns = ['Churn'])\n",
    "        y = df_set1.Churn \n",
    "        \n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 10,stratify = y)\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        predict = model.predict(X_test)\n",
    "        predict = np.round(predict)\n",
    "        print(classification_report(y_test,predict))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OverSampling(y0,y1,df):\n",
    "        \n",
    "        class_0_count,class_1_count = df.Churn.value_counts()\n",
    "        high_count = max(class_0_count,class_1_count)\n",
    "        \n",
    "        if high_count == class_0_count:\n",
    "            y1_DS = y1.sample(high_count,replace = True)\n",
    "#             Here we down sample y1\n",
    "            df_set1 = pd.concat([y1_DS,y0])\n",
    "    \n",
    "        if high_count == class_1_count:\n",
    "            y0_DS = y0.sample(high_count,replace = True)\n",
    "#             Here we down sample y1\n",
    "            df_set1 = pd.concat([y0_DS,y1])\n",
    "    \n",
    "        X = df_set1.drop(columns = ['Churn'])\n",
    "        y = df_set1.Churn \n",
    "        \n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 10,stratify = y)\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        predict = model.predict(X_test)\n",
    "        predict = np.round(predict)\n",
    "        print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmtSampling(X,y,df):\n",
    "        \n",
    "        smt = SMOTE(sampling_strategy='minority')\n",
    "        X,y = smt.fit_resample(X,y)\n",
    "        \n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 10)\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        predict = model.predict(X_test)\n",
    "        predict = np.round(predict)\n",
    "        print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       374\n",
      "           1       0.75      0.78      0.77       374\n",
      "\n",
      "    accuracy                           0.76       748\n",
      "   macro avg       0.76      0.76      0.76       748\n",
      "weighted avg       0.76      0.76      0.76       748\n",
      "\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1035\n",
      "           1       0.76      0.81      0.78      1035\n",
      "\n",
      "    accuracy                           0.77      2070\n",
      "   macro avg       0.78      0.77      0.77      2070\n",
      "weighted avg       0.78      0.77      0.77      2070\n",
      "\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1057\n",
      "           1       0.79      0.84      0.81      1013\n",
      "\n",
      "    accuracy                           0.81      2070\n",
      "   macro avg       0.81      0.81      0.81      2070\n",
      "weighted avg       0.81      0.81      0.81      2070\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apoor\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print(DownSampling(class_0,class_1,df))\n",
    "print(OverSampling(class_0,class_1,df))\n",
    "print(SmtSampling(X,y,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here in each case accuracy and f1-score is increased due to sampling of imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
